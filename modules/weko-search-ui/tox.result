GLOB sdist-make: /code/modules/weko-search-ui/setup.py
c1 inst-nodeps: /code/modules/weko-search-ui/.tox/.tmp/package/1/weko-search-ui-0.1.0.dev20170000.zip
c1 installed: alabaster==0.7.13,alembic==0.9.6,amqp==2.6.1,angular-gettext-babel==0.3,aniso8601==8.0.0,arrow==0.12.1,asn1crypto==0.23.0,attrs==17.4.0,b2handle==1.1.2,Babel==2.5.1,bagit==1.7.0,beautifulsoup4==4.9.3,bibtexparser==1.0.1,billiard==3.6.3.0,binaryornot==0.4.4,bleach==3.1.0,blinker==1.4,boto3==1.7.84,botocore==1.10.84,cachelib==0.1,cachetools==4.2.4,cchardet==2.1.1,celery==4.4.7,certifi==2017.11.5,cffi==1.11.2,chardet==3.0.4,citeproc-py==0.5.1,citeproc-py-styles==0.1.2,click==8.0.4,cookiecutter==1.6.0,counter-robots==2018.6,coverage==6.2,cryptography==2.1.4,datacite==1.0.1,DateTime==4.9,decorator==4.1.2,defusedxml==0.5.0,dictdiffer==0.7.0,dnspython==2.2.1,docutils==0.18.1,dojson==1.3.2,elasticsearch==6.1.1,elasticsearch-dsl==6.4.0,elementpath==1.0.6,email-validator==1.0.5,entrypoints==0.2.3,feedgen==0.7.0,Flask==1.0.4,Flask-Admin==1.5.3,Flask-Alembic==2.0.1,Flask-Assets==0.12,Flask-BabelEx==0.9.4,Flask-Breadcrumbs==0.5.0,Flask-Caching==1.3.3,Flask-CeleryExt==0.3.4,Flask-Collect==1.2.2,Flask-Cors==3.0.3,Flask-DebugToolbar==0.11.0,Flask-IIIF==0.6.1,Flask-KVSession==0.6.2,Flask-Limiter==1.1.0,Flask-Login==0.4.1,Flask-Mail==0.9.1,flask-marshmallow==0.14.0,Flask-Menu==0.6.0,Flask-OAuthlib==0.9.5,Flask-Plugins==1.6.1,Flask-Principal==0.4.0,Flask-RESTful==0.3.8,Flask-Security==3.0.0,flask-shell-ipython==0.4.1,Flask-Sitemap==0.1.0,Flask-SQLAlchemy==2.3.2,flask-talisman==0.4.1,Flask-WTF==0.14.3,-e git+https://github.com/RCOSDP/pyfpdf.git@f9b032148283d535cabc7789858081c80de36fef#egg=fpdf,frozendict==2.3.8,fs==0.5.4,ftfy==4.4.3,future==0.16.0,github3.py==1.1.0,html5lib==1.0.1,idna==2.6,iiif-prezi==0.3.0,imagesize==1.4.1,importlib-metadata==4.8.3,importlib-resources==5.4.0,infinity==1.4,iniconfig==1.1.1,intervals==0.8.0,invenio-access==1.1.0,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_accounts&subdirectory=modules/invenio-accounts,invenio-admin==1.1.2,invenio-app==1.1.0,invenio-assets==1.0.0,invenio-base==1.0.2,invenio-cache==1.0.0,invenio-celery==1.1.3,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_communities&subdirectory=modules/invenio-communities,invenio-config==1.0.0,invenio-csl-rest==1.0.0a1,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_db&subdirectory=modules/invenio-db,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_deposit&subdirectory=modules/invenio-deposit,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_files_rest&subdirectory=modules/invenio-files-rest,invenio-formatter==1.0.0b3,invenio-i18n==1.0.0,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_iiif&subdirectory=modules/invenio-iiif,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_indexer&subdirectory=modules/invenio-indexer,invenio-jsonschemas==1.0.0,invenio-logging==1.0.0b3,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_mail&subdirectory=modules/invenio-mail,invenio-marc21==1.0.0a8,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_oaiharvester&subdirectory=modules/invenio-oaiharvester,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_oaiserver&subdirectory=modules/invenio-oaiserver,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_oauth2server&subdirectory=modules/invenio-oauth2server,invenio-oauthclient==1.0.0,invenio-pidrelations==1.0.0a4,invenio-pidstore==1.0.0,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_previewer&subdirectory=modules/invenio-previewer,invenio-query-parser==0.6.0,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_queues&subdirectory=modules/invenio-queues,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_records&subdirectory=modules/invenio-records,invenio-records-files==1.0.0a10,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_records_rest&subdirectory=modules/invenio-records-rest,invenio-records-ui==1.0.0,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_resourcesyncclient&subdirectory=modules/invenio-resourcesyncclient,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_resourcesyncserver&subdirectory=modules/invenio-resourcesyncserver,invenio-rest==1.1.2,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_s3&subdirectory=modules/invenio-s3,invenio-search==1.1.0,invenio-search-ui==1.0.0a9,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=invenio_stats&subdirectory=modules/invenio-stats,invenio-theme==1.0.0b4,ipaddress==1.0.19,ipython==6.2.1,ipython-genutils==0.2.0,itsdangerous==0.24,jedi==0.11.0,Jinja2==2.10,jinja2-cli==0.6.0,jinja2-time==0.2.0,jmespath==0.10.0,jsmin==2.2.2,jsonpatch==1.21,jsonpath-ng==1.5.2,jsonpointer==1.14,jsonref==0.1,jsonresolver==0.2.1,jsonschema==2.6.0,jupyter-client==5.2.2,jupyter-core==4.4.0,-e git+https://github.com/RCOSDP/kombu.git@f204fdf078d5e94393c86693f545e2d011f620f5#egg=kombu,limits==1.2.1,lxml==4.1.1,Mako==1.0.7,MarkupSafe==1.1.1,marshmallow==2.20.1,marshmallow-sqlalchemy==0.23.1,maxminddb==1.5.2,maxminddb-geolite2==2017.803,mistune==0.8.3,mock==3.0.5,more-itertools==8.10.0,msgpack==0.6.2,nbconvert==5.3.1,nbformat==4.4.0,netaddr==0.8.0,node-semver==0.1.1,numpy==1.16.1,oauthlib==2.1.0,ordereddict==1.1,packaging==21.3,pandocfilters==1.4.2,parso==0.1.0,passlib==1.7.1,pexpect==4.3.0,pickleshare==0.7.4,Pillow==5.4.1,pluggy==0.13.1,ply==3.11,poyo==0.4.1,prompt-toolkit==1.0.15,psycopg2==2.7.3.2,ptyprocess==0.5.2,py==1.11.0,pycparser==2.18,Pygments==2.2.0,PyJWT==1.5.3,PyLD==2.0.3,pyparsing==3.1.1,-e git+https://github.com/RCOSDP/PyPDF2.git@fefc684a3a74aff6f99e5dff24f9b4dd1c95169d#egg=PyPDF2,pyPEG2==2.15.2,pytest==6.1.2,pytest-cov==4.0.0,pytest-mock==3.6.1,python-dateutil==2.6.1,python-editor==1.0.3,python-geoip==1.2,pytz==2017.3,pyzmq==17.0.0,redis==2.10.6,requests==2.18.4,requests-oauthlib==1.1.0,resync==1.0.9,s3fs==0.1.6,s3transfer==0.1.13,Sickle==0.6.4,simplegeneric==0.8.1,simplejson==3.12.0,simplekv==0.11.2,six==1.12.0,snowballstemmer==2.2.0,soupsieve==2.3.2.post1,speaklater==1.3,Sphinx==1.8.4,sphinxcontrib-serializinghtml==1.1.5,sphinxcontrib-websupport==1.2.4,SQLAlchemy==1.2.19,SQLAlchemy-Continuum==1.3.6,SQLAlchemy-Utils==0.35.0,testpath==0.3.1,toml==0.10.2,tomli==1.2.3,tornado==4.5.3,traitlets==4.3.2,typing_extensions==4.1.1,ua-parser==0.7.3,uritemplate==4.1.1,uritools==2.1.0,urllib3==1.22,validators==0.12.0,vine==1.3.0,Wand==0.6.1,wcwidth==0.1.7,webargs==5.5.2,webassets==0.12.1,webencodings==0.5.1,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_accounts&subdirectory=modules/weko-accounts,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_admin&subdirectory=modules/weko-admin,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_authors&subdirectory=modules/weko-authors,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_bulkupdate&subdirectory=modules/weko-bulkupdate,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_deposit&subdirectory=modules/weko-deposit,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_gridlayout&subdirectory=modules/weko-gridlayout,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_groups&subdirectory=modules/weko-groups,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_handle&subdirectory=modules/weko-handle,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_index_tree&subdirectory=modules/weko-index-tree,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_indextree_journal&subdirectory=modules/weko-indextree-journal,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_items_autofill&subdirectory=modules/weko-items-autofill,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_items_ui&subdirectory=modules/weko-items-ui,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_itemtypes_ui&subdirectory=modules/weko-itemtypes-ui,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_logging&subdirectory=modules/weko-logging,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_records&subdirectory=modules/weko-records,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_records_ui&subdirectory=modules/weko-records-ui,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_redis&subdirectory=modules/weko-redis,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_schema_ui&subdirectory=modules/weko-schema-ui,weko-search-ui @ file:///code/modules/weko-search-ui/.tox/.tmp/package/1/weko-search-ui-0.1.0.dev20170000.zip,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_sitemap&subdirectory=modules/weko-sitemap,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_theme&subdirectory=modules/weko-theme,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_user_profiles&subdirectory=modules/weko-user-profiles,-e git+https://mhaya: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@github.com/RCOSDP/weko.git@9681d8d89512eb9df7e6eb70c311342468e65c50#egg=weko_workflow&subdirectory=modules/weko-workflow,Werkzeug==0.15.2,whichcraft==0.4.1,WTForms==2.1,WTForms-Alchemy==0.16.5,WTForms-Components==0.10.3,xmlschema==0.9.30,xmltodict==0.12.0,zipp==3.6.0,zope.interface==5.5.2
c1 run-test-pre: PYTHONHASHSEED='3968601603'
c1 run-test: commands[0] | pytest --cov=weko_search_ui tests -v --cov-branch --cov-report=term --cov-report=xml --cov-report=html --cov-config=tox.ini --basetemp=/code/modules/weko-search-ui/.tox/c1/tmp
============================= test session starts ==============================
platform linux -- Python 3.6.15, pytest-6.1.2, py-1.11.0, pluggy-0.13.1 -- /code/modules/weko-search-ui/.tox/c1/bin/python
cachedir: .tox/c1/.pytest_cache
rootdir: /code/modules/weko-search-ui
plugins: celery-4.4.7, mock-3.6.1, cov-4.0.0
collecting ... collected 378 items

tests/test_admin.py::test_ItemManagementBulkDelete_index PASSED          [  0%]
tests/test_admin.py::test_ItemManagementBulkDelete_check PASSED          [  0%]
tests/test_admin.py::TestItemManagementCustomSort::test_index_acl PASSED [  0%]
tests/test_admin.py::test_ItemManagementCustomSort_save_sort PASSED      [  1%]
tests/test_admin.py::TestItemManagementBulkSearch::test_index_acl FAILED [  1%]
tests/test_admin.py::test_ItemManagementBulkSearch_is_visible PASSED     [  1%]
tests/test_admin.py::TestItemImportView::test_index_acl PASSED           [  1%]
tests/test_admin.py::test_ItemImportView_check FAILED                    [  2%]
tests/test_admin.py::test_ItemImportView_get_check_status PASSED         [  2%]
tests/test_admin.py::test_ItemImportView_download_check PASSED           [  2%]
tests/test_admin.py::test_ItemImportView_import_items PASSED             [  2%]
tests/test_admin.py::test_ItemImportView_get_status PASSED               [  3%]
tests/test_admin.py::test_ItemImportView_download_import PASSED          [  3%]
tests/test_admin.py::test_ItemImportView_get_disclaimer_text PASSED      [  3%]
tests/test_admin.py::test_ItemImportView_export_template PASSED          [  3%]
tests/test_admin.py::test_ItemBulkExport_index PASSED                    [  4%]
tests/test_admin.py::TestItemBulkExport::test_check_export_status FAILED [  4%]
tests/test_admin.py::TestItemBulkExport::test_cancel_export PASSED       [  4%]
tests/test_admin.py::test_export_template PASSED                         [  5%]
tests/test_api.py::test_get_results_setting PASSED                       [  5%]
tests/test_api.py::test_get_default_sort PASSED                          [  5%]
tests/test_api.py::test_get_sort_key PASSED                              [  5%]
tests/test_api.py::test_get_custom_sort PASSED                           [  6%]
tests/test_api.py::test_get_nested_sorting PASSED                        [  6%]
tests/test_api.py::test_get_search_detail_keyword PASSED                 [  6%]
tests/test_api.py::test_get_childinfo PASSED                             [  6%]
tests/test_api.py::test_escape_str PASSED                                [  7%]
tests/test_bundles.py::test_catalog PASSED                               [  7%]
tests/test_ext.py::test_WekoSearchUI PASSED                              [  7%]
tests/test_ext.py::test_WekoSearchUI_2 PASSED                            [  7%]
tests/test_ext.py::test_WekoSearchREST PASSED                            [  8%]
tests/test_links.py::test_default_links_factory PASSED                   [  8%]
tests/test_query.py::test_get_item_type_aggs PASSED                      [  8%]
tests/test_query.py::test_get_permission_filter PASSED                   [  8%]
tests/test_query.py::test_default_search_factory PASSED                  [  9%]
tests/test_query.py::test_item_path_search_factory FAILED                [  9%]
tests/test_query.py::test_check_permission_user PASSED                   [  9%]
tests/test_query.py::test_opensearch_factory PASSED                      [ 10%]
tests/test_query.py::test_item_search_factory PASSED                     [ 10%]
tests/test_query.py::test_feedback_email_search_factory PASSED           [ 10%]
tests/test_query.py::test_function_issue35902 FAILED                     [ 10%]
tests/test_rest.py::test_IndexSearchResource_get_Exception FAILED        [ 11%]
tests/test_rest.py::test_IndexSearchResource_get_MaxResultWindowRESTError PASSED [ 11%]
tests/test_rest.py::test_create_blueprint PASSED                         [ 11%]
tests/test_rest.py::test_IndexSearchResource_get PASSED                  [ 11%]
tests/test_rest.py::test_get_heading_info PASSED                         [ 12%]
tests/test_tasks.py::test_check_import_items_task PASSED                 [ 12%]
tests/test_tasks.py::test_import_item PASSED                             [ 12%]
tests/test_tasks.py::test_remove_temp_dir_task PASSED                    [ 12%]
tests/test_tasks.py::test_delete_task_id_cache PASSED                    [ 13%]
tests/test_tasks.py::test_export_all_task PASSED                         [ 13%]
tests/test_tasks.py::test_delete_exported_task PASSED                    [ 13%]
tests/test_tasks.py::test_is_import_running PASSED                       [ 14%]
tests/test_tasks.py::test_check_celery_is_run PASSED                     [ 14%]
tests/test_utils.py::test_DefaultOrderDict_deepcopy PASSED               [ 14%]
tests/test_utils.py::test_get_tree_items PASSED                          [ 14%]
tests/test_utils.py::test_delete_records FAILED                          [ 15%]
tests/test_utils.py::test_get_journal_info PASSED                        [ 15%]
tests/test_utils.py::test_get_feedback_mail_list FAILED                  [ 15%]
tests/test_utils.py::test_check_permission PASSED                        [ 15%]
tests/test_utils.py::test_get_content_workflow PASSED                    [ 16%]
tests/test_utils.py::test_set_nested_item PASSED                         [ 16%]
tests/test_utils.py::test_define_default_dict PASSED                     [ 16%]
tests/test_utils.py::test_defaultify PASSED                              [ 16%]
tests/test_utils.py::test_handle_generate_key_path PASSED                [ 17%]
tests/test_utils.py::test_parse_to_json_form PASSED                      [ 17%]
tests/test_utils.py::test_check_import_items PASSED                      [ 17%]
tests/test_utils.py::test_unpackage_import_file FAILED                   [ 17%]
tests/test_utils.py::test_getEncode PASSED                               [ 18%]
tests/test_utils.py::test_read_stats_file FAILED                         [ 18%]
tests/test_utils.py::test_handle_convert_validate_msg_to_jp PASSED       [ 18%]
tests/test_utils.py::test_handle_validate_item_import PASSED             [ 19%]
tests/test_utils.py::test_represents_int PASSED                          [ 19%]
tests/test_utils.py::test_get_item_type PASSED                           [ 19%]
tests/test_utils.py::test_handle_check_exist_record PASSED               [ 19%]
tests/test_utils.py::test_make_file_by_line PASSED                       [ 20%]
tests/test_utils.py::test_make_stats_file PASSED                         [ 20%]
tests/test_utils.py::test_create_deposit PASSED                          [ 20%]
tests/test_utils.py::test_clean_thumbnail_file PASSED                    [ 20%]
tests/test_utils.py::test_up_load_file ERROR                             [ 21%]
tests/test_utils.py::test_up_load_file ERROR                             [ 21%]
tests/test_utils.py::test_get_file_name PASSED                           [ 21%]
tests/test_utils.py::test_register_item_metadata ERROR                   [ 21%]
tests/test_utils.py::test_update_publish_status ERROR                    [ 21%]
tests/test_utils.py::test_handle_workflow ERROR                          [ 22%]
tests/test_utils.py::test_create_work_flow PASSED                        [ 22%]
tests/test_utils.py::test_create_flow_define PASSED                      [ 22%]
tests/test_utils.py::test_send_item_created_event_to_es ERROR            [ 23%]
tests/test_utils.py::test_import_items_to_system ERROR                   [ 23%]
tests/test_utils.py::test_handle_item_title ERROR                        [ 23%]
tests/test_utils.py::test_handle_check_and_prepare_publish_status PASSED [ 23%]
tests/test_utils.py::test_handle_check_and_prepare_index_tree FAILED     [ 24%]
tests/test_utils.py::test_handle_check_and_prepare_index_tree2 FAILED    [ 24%]
tests/test_utils.py::test_handle_check_and_prepare_feedback_mail FAILED  [ 24%]
tests/test_utils.py::test_handle_set_change_identifier_flag PASSED       [ 24%]
tests/test_utils.py::test_handle_check_cnri FAILED                       [ 25%]
tests/test_utils.py::test_handle_check_cnri_2 PASSED                     [ 25%]
tests/test_utils.py::test_handle_check_doi_indexes ERROR                 [ 25%]
tests/test_utils.py::test_handle_check_doi_ra ERROR                      [ 25%]
tests/test_utils.py::test_handle_check_doi FAILED                        [ 26%]
tests/test_utils.py::test_register_item_handle ERROR                     [ 26%]
tests/test_utils.py::test_prepare_doi_setting PASSED                     [ 26%]
tests/test_utils.py::test_get_doi_prefix[JaLC] PASSED                    [ 26%]
tests/test_utils.py::test_get_doi_prefix[Crossref] PASSED                [ 27%]
tests/test_utils.py::test_get_doi_prefix[DataCite] PASSED                [ 27%]
tests/test_utils.py::test_get_doi_prefix[NDL JaLC] PASSED                [ 27%]
tests/test_utils.py::test_get_doi_link PASSED                            [ 28%]
tests/test_utils.py::test_prepare_doi_link PASSED                        [ 28%]
tests/test_utils.py::test_register_item_doi ERROR                        [ 28%]
tests/test_utils.py::test_register_item_update_publish_status ERROR      [ 28%]
tests/test_utils.py::test_handle_doi_required_check ERROR                [ 29%]
tests/test_utils.py::test_handle_check_date PASSED                       [ 29%]
tests/test_utils.py::test_handle_check_id PASSED                         [ 29%]
tests/test_utils.py::test_get_data_in_deep_dict PASSED                   [ 29%]
tests/test_utils.py::test_validation_file_open_date PASSED               [ 30%]
tests/test_utils.py::test_validation_date_property PASSED                [ 30%]
tests/test_utils.py::test_get_list_key_of_iso_date PASSED                [ 30%]
tests/test_utils.py::test_get_current_language PASSED                    [ 30%]
tests/test_utils.py::test_get_change_identifier_mode_content PASSED      [ 31%]
tests/test_utils.py::test_get_root_item_option PASSED                    [ 31%]
tests/test_utils.py::test_get_sub_item_option PASSED                     [ 31%]
tests/test_utils.py::test_check_sub_item_is_system PASSED                [ 32%]
tests/test_utils.py::test_get_lifetime PASSED                            [ 32%]
tests/test_utils.py::test_get_system_data_uri PASSED                     [ 32%]
tests/test_utils.py::test_handle_fill_system_item FAILED                 [ 32%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi0-after_doi0-warnings0-errors0-False-False] ERROR [ 33%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi1-after_doi1-warnings1-errors1-False-False] ERROR [ 33%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi2-after_doi2-warnings2-errors2-False-False] ERROR [ 33%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi3-after_doi3-warnings3-errors3-False-False] ERROR [ 33%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi4-after_doi4-warnings4-errors4-False-False] ERROR [ 34%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi5-after_doi5-warnings5-errors5-False-False] ERROR [ 34%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi6-after_doi6-warnings6-errors6-False-False] ERROR [ 34%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi7-after_doi7-warnings7-errors7-False-False] ERROR [ 34%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi8-after_doi8-warnings8-errors8-False-False] ERROR [ 35%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi9-after_doi9-warnings9-errors9-False-False] ERROR [ 35%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi10-after_doi10-warnings10-errors10-False-False] ERROR [ 35%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi11-after_doi11-warnings11-errors11-False-False] ERROR [ 35%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi12-after_doi12-warnings12-errors12-False-False] ERROR [ 36%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi13-after_doi13-warnings13-errors13-False-False] ERROR [ 36%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi14-after_doi14-warnings14-errors14-False-False] ERROR [ 36%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi15-after_doi15-warnings15-errors15-False-False] ERROR [ 37%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi16-after_doi16-warnings16-errors16-False-False] ERROR [ 37%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi17-after_doi17-warnings17-errors17-True-False] ERROR [ 37%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi18-after_doi18-warnings18-errors18-True-False] ERROR [ 37%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi19-after_doi19-warnings19-errors19-True-False] ERROR [ 38%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi20-after_doi20-warnings20-errors20-True-False] ERROR [ 38%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi21-after_doi21-warnings21-errors21-True-False] ERROR [ 38%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi22-after_doi22-warnings22-errors22-True-False] ERROR [ 38%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi23-after_doi23-warnings23-errors23-True-False] ERROR [ 39%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi24-after_doi24-warnings24-errors24-True-False] ERROR [ 39%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi25-after_doi25-warnings25-errors25-True-False] ERROR [ 39%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi26-after_doi26-warnings26-errors26-True-False] ERROR [ 39%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi27-after_doi27-warnings27-errors27-True-False] ERROR [ 40%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi28-after_doi28-warnings28-errors28-True-False] ERROR [ 40%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi29-after_doi29-warnings29-errors29-True-False] ERROR [ 40%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi30-after_doi30-warnings30-errors30-True-False] ERROR [ 41%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi31-after_doi31-warnings31-errors31-True-False] ERROR [ 41%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi32-after_doi32-warnings32-errors32-True-False] ERROR [ 41%]
tests/test_utils.py::test_handle_fill_system_item3[1-before_doi33-after_doi33-warnings33-errors33-True-False] ERROR [ 41%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi34-after_doi34-warnings34-errors34-False-False] ERROR [ 42%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi35-after_doi35-warnings35-errors35-False-False] ERROR [ 42%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi36-after_doi36-warnings36-errors36-False-False] ERROR [ 42%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi37-after_doi37-warnings37-errors37-False-False] ERROR [ 42%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi38-after_doi38-warnings38-errors38-False-False] ERROR [ 43%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi39-after_doi39-warnings39-errors39-False-False] ERROR [ 43%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi40-after_doi40-warnings40-errors40-False-False] ERROR [ 43%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi41-after_doi41-warnings41-errors41-False-False] ERROR [ 43%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi42-after_doi42-warnings42-errors42-False-False] ERROR [ 44%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi43-after_doi43-warnings43-errors43-False-False] ERROR [ 44%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi44-after_doi44-warnings44-errors44-False-False] ERROR [ 44%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi45-after_doi45-warnings45-errors45-False-False] ERROR [ 44%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi46-after_doi46-warnings46-errors46-False-False] ERROR [ 45%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi47-after_doi47-warnings47-errors47-False-False] ERROR [ 45%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi48-after_doi48-warnings48-errors48-False-False] ERROR [ 45%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi49-after_doi49-warnings49-errors49-False-False] ERROR [ 46%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi50-after_doi50-warnings50-errors50-False-False] ERROR [ 46%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi51-after_doi51-warnings51-errors51-True-False] ERROR [ 46%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi52-after_doi52-warnings52-errors52-True-False] ERROR [ 46%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi53-after_doi53-warnings53-errors53-True-False] ERROR [ 47%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi54-after_doi54-warnings54-errors54-True-False] ERROR [ 47%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi55-after_doi55-warnings55-errors55-True-False] ERROR [ 47%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi56-after_doi56-warnings56-errors56-True-False] ERROR [ 47%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi57-after_doi57-warnings57-errors57-True-False] ERROR [ 48%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi58-after_doi58-warnings58-errors58-True-False] ERROR [ 48%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi59-after_doi59-warnings59-errors59-True-False] ERROR [ 48%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi60-after_doi60-warnings60-errors60-True-False] ERROR [ 48%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi61-after_doi61-warnings61-errors61-True-False] ERROR [ 49%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi62-after_doi62-warnings62-errors62-True-False] ERROR [ 49%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi63-after_doi63-warnings63-errors63-True-False] ERROR [ 49%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi64-after_doi64-warnings64-errors64-True-False] ERROR [ 50%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi65-after_doi65-warnings65-errors65-True-False] ERROR [ 50%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi66-after_doi66-warnings66-errors66-True-False] ERROR [ 50%]
tests/test_utils.py::test_handle_fill_system_item3[2-before_doi67-after_doi67-warnings67-errors67-True-False] ERROR [ 50%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi68-after_doi68-warnings68-errors68-False-False] ERROR [ 51%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi69-after_doi69-warnings69-errors69-False-False] ERROR [ 51%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi70-after_doi70-warnings70-errors70-False-False] ERROR [ 51%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi71-after_doi71-warnings71-errors71-False-False] ERROR [ 51%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi72-after_doi72-warnings72-errors72-False-False] ERROR [ 52%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi73-after_doi73-warnings73-errors73-False-False] ERROR [ 52%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi74-after_doi74-warnings74-errors74-False-False] ERROR [ 52%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi75-after_doi75-warnings75-errors75-False-False] ERROR [ 52%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi76-after_doi76-warnings76-errors76-False-False] ERROR [ 53%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi77-after_doi77-warnings77-errors77-False-False] ERROR [ 53%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi78-after_doi78-warnings78-errors78-False-False] ERROR [ 53%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi79-after_doi79-warnings79-errors79-False-False] ERROR [ 53%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi80-after_doi80-warnings80-errors80-False-False] ERROR [ 54%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi81-after_doi81-warnings81-errors81-False-False] ERROR [ 54%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi82-after_doi82-warnings82-errors82-False-False] ERROR [ 54%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi83-after_doi83-warnings83-errors83-False-False] ERROR [ 55%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi84-after_doi84-warnings84-errors84-False-False] ERROR [ 55%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi85-after_doi85-warnings85-errors85-True-False] ERROR [ 55%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi86-after_doi86-warnings86-errors86-True-False] ERROR [ 55%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi87-after_doi87-warnings87-errors87-True-False] ERROR [ 56%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi88-after_doi88-warnings88-errors88-True-False] ERROR [ 56%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi89-after_doi89-warnings89-errors89-True-False] ERROR [ 56%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi90-after_doi90-warnings90-errors90-True-False] ERROR [ 56%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi91-after_doi91-warnings91-errors91-True-False] ERROR [ 57%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi92-after_doi92-warnings92-errors92-True-False] ERROR [ 57%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi93-after_doi93-warnings93-errors93-True-False] ERROR [ 57%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi94-after_doi94-warnings94-errors94-True-False] ERROR [ 57%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi95-after_doi95-warnings95-errors95-True-False] ERROR [ 58%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi96-after_doi96-warnings96-errors96-True-False] ERROR [ 58%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi97-after_doi97-warnings97-errors97-True-False] ERROR [ 58%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi98-after_doi98-warnings98-errors98-True-False] ERROR [ 58%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi99-after_doi99-warnings99-errors99-True-False] ERROR [ 59%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi100-after_doi100-warnings100-errors100-True-False] ERROR [ 59%]
tests/test_utils.py::test_handle_fill_system_item3[3-before_doi101-after_doi101-warnings101-errors101-True-False] ERROR [ 59%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi102-after_doi102-warnings102-errors102-False-False] ERROR [ 60%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi103-after_doi103-warnings103-errors103-False-False] ERROR [ 60%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi104-after_doi104-warnings104-errors104-False-False] ERROR [ 60%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi105-after_doi105-warnings105-errors105-False-False] ERROR [ 60%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi106-after_doi106-warnings106-errors106-False-False] ERROR [ 61%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi107-after_doi107-warnings107-errors107-False-False] ERROR [ 61%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi108-after_doi108-warnings108-errors108-False-False] ERROR [ 61%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi109-after_doi109-warnings109-errors109-False-False] ERROR [ 61%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi110-after_doi110-warnings110-errors110-False-False] ERROR [ 62%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi111-after_doi111-warnings111-errors111-False-False] ERROR [ 62%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi112-after_doi112-warnings112-errors112-False-False] ERROR [ 62%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi113-after_doi113-warnings113-errors113-False-False] ERROR [ 62%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi114-after_doi114-warnings114-errors114-False-False] ERROR [ 63%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi115-after_doi115-warnings115-errors115-False-False] ERROR [ 63%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi116-after_doi116-warnings116-errors116-False-False] ERROR [ 63%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi117-after_doi117-warnings117-errors117-False-False] ERROR [ 64%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi118-after_doi118-warnings118-errors118-False-False] ERROR [ 64%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi119-after_doi119-warnings119-errors119-True-False] ERROR [ 64%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi120-after_doi120-warnings120-errors120-True-False] ERROR [ 64%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi121-after_doi121-warnings121-errors121-True-False] ERROR [ 65%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi122-after_doi122-warnings122-errors122-True-False] ERROR [ 65%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi123-after_doi123-warnings123-errors123-True-False] ERROR [ 65%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi124-after_doi124-warnings124-errors124-True-False] ERROR [ 65%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi125-after_doi125-warnings125-errors125-True-False] ERROR [ 66%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi126-after_doi126-warnings126-errors126-True-False] ERROR [ 66%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi127-after_doi127-warnings127-errors127-True-False] ERROR [ 66%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi128-after_doi128-warnings128-errors128-True-False] ERROR [ 66%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi129-after_doi129-warnings129-errors129-True-False] ERROR [ 67%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi130-after_doi130-warnings130-errors130-True-False] ERROR [ 67%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi131-after_doi131-warnings131-errors131-True-False] ERROR [ 67%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi132-after_doi132-warnings132-errors132-True-False] ERROR [ 67%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi133-after_doi133-warnings133-errors133-True-False] ERROR [ 68%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi134-after_doi134-warnings134-errors134-True-False] ERROR [ 68%]
tests/test_utils.py::test_handle_fill_system_item3[4-before_doi135-after_doi135-warnings135-errors135-True-False] ERROR [ 68%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi136-after_doi136-warnings136-errors136-False-False] ERROR [ 69%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi137-after_doi137-warnings137-errors137-False-False] ERROR [ 69%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi138-after_doi138-warnings138-errors138-False-False] ERROR [ 69%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi139-after_doi139-warnings139-errors139-False-False] ERROR [ 69%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi140-after_doi140-warnings140-errors140-False-False] ERROR [ 70%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi141-after_doi141-warnings141-errors141-False-False] ERROR [ 70%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi142-after_doi142-warnings142-errors142-False-False] ERROR [ 70%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi143-after_doi143-warnings143-errors143-False-False] ERROR [ 70%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi144-after_doi144-warnings144-errors144-False-False] ERROR [ 71%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi145-after_doi145-warnings145-errors145-False-False] ERROR [ 71%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi146-after_doi146-warnings146-errors146-False-False] ERROR [ 71%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi147-after_doi147-warnings147-errors147-False-False] ERROR [ 71%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi148-after_doi148-warnings148-errors148-False-False] ERROR [ 72%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi149-after_doi149-warnings149-errors149-False-False] ERROR [ 72%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi150-after_doi150-warnings150-errors150-False-False] ERROR [ 72%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi151-after_doi151-warnings151-errors151-False-False] ERROR [ 73%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi152-after_doi152-warnings152-errors152-False-False] ERROR [ 73%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi153-after_doi153-warnings153-errors153-False-False] ERROR [ 73%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi154-after_doi154-warnings154-errors154-False-False] ERROR [ 73%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi155-after_doi155-warnings155-errors155-False-False] ERROR [ 74%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi156-after_doi156-warnings156-errors156-False-False] ERROR [ 74%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi157-after_doi157-warnings157-errors157-False-False] ERROR [ 74%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi158-after_doi158-warnings158-errors158-False-False] ERROR [ 74%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi159-after_doi159-warnings159-errors159-True-False] ERROR [ 75%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi160-after_doi160-warnings160-errors160-True-False] ERROR [ 75%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi161-after_doi161-warnings161-errors161-True-False] ERROR [ 75%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi162-after_doi162-warnings162-errors162-True-False] ERROR [ 75%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi163-after_doi163-warnings163-errors163-True-False] ERROR [ 76%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi164-after_doi164-warnings164-errors164-True-False] ERROR [ 76%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi165-after_doi165-warnings165-errors165-True-False] ERROR [ 76%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi166-after_doi166-warnings166-errors166-True-False] ERROR [ 76%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi167-after_doi167-warnings167-errors167-True-False] ERROR [ 77%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi168-after_doi168-warnings168-errors168-True-False] ERROR [ 77%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi169-after_doi169-warnings169-errors169-True-False] ERROR [ 77%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi170-after_doi170-warnings170-errors170-True-False] ERROR [ 78%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi171-after_doi171-warnings171-errors171-True-False] ERROR [ 78%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi172-after_doi172-warnings172-errors172-True-False] ERROR [ 78%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi173-after_doi173-warnings173-errors173-True-False] ERROR [ 78%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi174-after_doi174-warnings174-errors174-True-False] ERROR [ 79%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi175-after_doi175-warnings175-errors175-True-False] ERROR [ 79%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi176-after_doi176-warnings176-errors176-True-False] ERROR [ 79%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi177-after_doi177-warnings177-errors177-True-False] ERROR [ 79%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi178-after_doi178-warnings178-errors178-True-False] ERROR [ 80%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi179-after_doi179-warnings179-errors179-True-False] ERROR [ 80%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi180-after_doi180-warnings180-errors180-True-False] ERROR [ 80%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi181-after_doi181-warnings181-errors181-True-False] ERROR [ 80%]
tests/test_utils.py::test_handle_fill_system_item3[5-before_doi182-after_doi182-warnings182-errors182-True-False] ERROR [ 81%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi183-after_doi183-warnings183-errors183-False-False] ERROR [ 81%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi184-after_doi184-warnings184-errors184-False-False] ERROR [ 81%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi185-after_doi185-warnings185-errors185-False-False] ERROR [ 82%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi186-after_doi186-warnings186-errors186-False-False] ERROR [ 82%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi187-after_doi187-warnings187-errors187-False-False] ERROR [ 82%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi188-after_doi188-warnings188-errors188-False-False] ERROR [ 82%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi189-after_doi189-warnings189-errors189-False-False] ERROR [ 83%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi190-after_doi190-warnings190-errors190-False-False] ERROR [ 83%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi191-after_doi191-warnings191-errors191-True-False] ERROR [ 83%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi192-after_doi192-warnings192-errors192-True-False] ERROR [ 83%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi193-after_doi193-warnings193-errors193-True-False] ERROR [ 84%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi194-after_doi194-warnings194-errors194-True-False] ERROR [ 84%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi195-after_doi195-warnings195-errors195-True-False] ERROR [ 84%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi196-after_doi196-warnings196-errors196-True-False] ERROR [ 84%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi197-after_doi197-warnings197-errors197-True-False] ERROR [ 85%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi198-after_doi198-warnings198-errors198-True-False] ERROR [ 85%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi199-after_doi199-warnings199-errors199-True-True] ERROR [ 85%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi200-after_doi200-warnings200-errors200-True-True] ERROR [ 85%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi201-after_doi201-warnings201-errors201-True-True] ERROR [ 86%]
tests/test_utils.py::test_handle_fill_system_item3[None-before_doi202-after_doi202-warnings202-errors202-True-True] ERROR [ 86%]
tests/test_utils.py::test_get_thumbnail_key ERROR                        [ 86%]
tests/test_utils.py::test_handle_check_thumbnail_file_type PASSED        [ 87%]
tests/test_utils.py::test_handle_check_metadata_not_existed ERROR        [ 87%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items0-.metadata.item_1657196790737[0]-text[0]-form0-ids0-names0] PASSED [ 87%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items1-.metadata.item_1657204077414[0]-list[0]-form1-ids1-names1] PASSED [ 87%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items2-.metadata.item_1657204070640-list-form2-ids2-names2] PASSED [ 88%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items3-.metadata.item_1657204026946-check-form3-ids3-names3] PASSED [ 88%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items4-.metadata.item_1657204036771[0]-check[0]-form4-ids4-names4] PASSED [ 88%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items5-.metadata.item_1657204043063-rad-form5-ids5-names5] PASSED [ 88%]
tests/test_utils.py::test_handle_get_all_sub_id_and_name[items6-.metadata.item_1657204049138[0]-rd[0]-form6-ids6-names6] PASSED [ 89%]
tests/test_utils.py::test_handle_get_all_id_in_item_type ERROR           [ 89%]
tests/test_utils.py::test_handle_check_consistence_with_mapping PASSED   [ 89%]
tests/test_utils.py::test_handle_check_duplication_item_id PASSED        [ 89%]
tests/test_utils.py::test_export_all ERROR                               [ 90%]
tests/test_utils.py::test_delete_exported ERROR                          [ 90%]
tests/test_utils.py::test_cancel_export_all ERROR                        [ 90%]
tests/test_utils.py::test_get_export_status ERROR                        [ 91%]
tests/test_utils.py::test_handle_check_item_is_locked ERROR              [ 91%]
tests/test_utils.py::test_handle_remove_es_metadata ERROR                [ 91%]
tests/test_utils.py::test_check_index_access_permissions ERROR           [ 91%]
tests/test_utils.py::test_handle_check_file_metadata PASSED              [ 92%]
tests/test_utils.py::test_handle_check_file_path PASSED                  [ 92%]
tests/test_utils.py::test_handle_check_file_content PASSED               [ 92%]
tests/test_utils.py::test_handle_check_thumbnail PASSED                  [ 92%]
tests/test_utils.py::test_get_key_by_property PASSED                     [ 93%]
tests/test_utils.py::test_get_data_by_property PASSED                    [ 93%]
tests/test_utils.py::test_get_filenames_from_metadata PASSED             [ 93%]
tests/test_utils.py::test_handle_check_filename_consistence PASSED       [ 93%]
tests/test_utils.py::test_function_issue34520[1-before_doi0-after_doi0-warnings0-errors0-True] ERROR [ 94%]
tests/test_utils.py::test_function_issue34535 ERROR                      [ 94%]
tests/test_utils.py::test_function_issue34958 ERROR                      [ 94%]
tests/test_utils.py::test_handle_fill_system_item_issue34520[1-before_doi0-after_doi0-warnings0-errors0-True] ERROR [ 94%]
tests/test_utils.py::test_handle_fill_system_item_issue34520[1000-before_doi1-after_doi1-warnings1-errors1-True] ERROR [ 95%]
tests/test_utils.py::test_handle_check_exist_record_issue35315[1-http://TEST_SERVER/records/1-warnings0-errors0-keep] ERROR [ 95%]
tests/test_utils.py::test_handle_check_exist_record_issue35315[1000-http://TEST_SERVER/records/1-warnings1-errors1-None] ERROR [ 95%]
tests/test_utils.py::test_handle_check_exist_record_issue35315[1000-http://TEST_SERVER/records/1000-warnings2-errors2-None] ERROR [ 96%]
tests/test_utils.py::test_handle_check_exist_record_issue35315[None-None-warnings3-errors3-new] ERROR [ 96%]
tests/test_utils.py::test_conbine_aggs PASSED                            [ 96%]
tests/test_views.py::test_search ERROR                                   [ 96%]
tests/test_views.py::test_search_acl_guest ERROR                         [ 97%]
tests/test_views.py::test_search_acl[3-200] ERROR                        [ 97%]
tests/test_views.py::test_opensearch_description ERROR                   [ 97%]
tests/test_views.py::test_opensearch_description_acl_guest ERROR         [ 97%]
tests/test_views.py::test_journal_detail ERROR                           [ 98%]
tests/test_views.py::test_search_feedback_mail_list ERROR                [ 98%]
tests/test_views.py::test_get_child_list ERROR                           [ 98%]
tests/test_views.py::test_get_path_name_dict ERROR                       [ 98%]
tests/test_views.py::test_gettitlefacet ERROR                            [ 99%]
tests/test_views.py::test_get_last_item_id ERROR                         [ 99%]
tests/test_weko_search_ui.py::test_version PASSED                        [ 99%]
tests/test_weko_search_ui.py::test_init PASSED                           [100%]

==================================== ERRORS ====================================
_____________________ ERROR at setup of test_up_load_file ______________________

db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
instance_path = '/var/tmp/tmpxvmyc3xl'
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]

    @pytest.fixture()
    def db_records2(db, instance_path, users):
        with db.session.begin_nested():
            Location.query.delete()
            loc = Location(name="local", uri=instance_path, default=True)
            db.session.add(loc)
        db.session.commit()
    
        record_data = json_data("data/test_records.json")
        item_data = json_data("data/test_items.json")
        record_num = len(record_data)
        result = []
        with db.session.begin_nested():
            for d in range(record_num):
>               result.append(create_record(record_data[d], item_data[d]))

tests/conftest.py:1165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/helpers.py:49: in create_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_alias/test-weko [status:400 request:0.004s]
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
____________________ ERROR at teardown of test_up_load_file ____________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
            list(current_search.create())
        except RequestError:
            list(current_search.delete(ignore=[404]))
            list(current_search.create(ignore=[400]))
        current_search_client.indices.refresh()
        yield current_search_client
>       list(current_search.delete(ignore=[404]))

tests/conftest.py:2763: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:340: in delete
    for result in _delete(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:332: in _delete
    for result in _delete(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:326: in _delete
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:423: in delete_alias
    '_alias', name), params=params)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_alias/test-weko [status:400 request:0.004s]
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
---------------------------- Captured log teardown -----------------------------
WARNING  elasticsearch:base.py:97 DELETE http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0,test-marc21-bibliographic-bd-v1.0.0,test-marc21-holdings-hd-v1.0.0/_alias/test-marc21 [status:403 request:0.004s]
________________ ERROR at setup of test_register_item_metadata _________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
_________________ ERROR at setup of test_update_publish_status _________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
____________________ ERROR at setup of test_handle_workflow ____________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
_____________ ERROR at setup of test_send_item_created_event_to_es _____________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.006s]
________________ ERROR at setup of test_import_items_to_system _________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.010s]
___________________ ERROR at setup of test_handle_item_title ___________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
_______________ ERROR at setup of test_handle_check_doi_indexes ________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
__________________ ERROR at setup of test_handle_check_doi_ra __________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
_________________ ERROR at setup of test_register_item_handle __________________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
___________________ ERROR at setup of test_register_item_doi ___________________

db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
instance_path = '/var/tmp/tmpk_tpm1tp'
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]

    @pytest.fixture()
    def db_records2(db, instance_path, users):
        with db.session.begin_nested():
            Location.query.delete()
            loc = Location(name="local", uri=instance_path, default=True)
            db.session.add(loc)
        db.session.commit()
    
        record_data = json_data("data/test_records.json")
        item_data = json_data("data/test_items.json")
        record_num = len(record_data)
        result = []
        with db.session.begin_nested():
            for d in range(record_num):
>               result.append(create_record(record_data[d], item_data[d]))

tests/conftest.py:1165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/helpers.py:49: in create_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.008s]
__________ ERROR at setup of test_register_item_update_publish_status __________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
_______________ ERROR at setup of test_handle_doi_required_check _______________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi0-after_doi0-warnings0-errors0-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi1-after_doi1-warnings1-errors1-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi2-after_doi2-warnings2-errors2-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi3-after_doi3-warnings3-errors3-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi4-after_doi4-warnings4-errors4-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi5-after_doi5-warnings5-errors5-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi6-after_doi6-warnings6-errors6-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi7-after_doi7-warnings7-errors7-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi8-after_doi8-warnings8-errors8-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi9-after_doi9-warnings9-errors9-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi10-after_doi10-warnings10-errors10-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi11-after_doi11-warnings11-errors11-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi12-after_doi12-warnings12-errors12-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi13-after_doi13-warnings13-errors13-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi14-after_doi14-warnings14-errors14-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi15-after_doi15-warnings15-errors15-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi16-after_doi16-warnings16-errors16-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi17-after_doi17-warnings17-errors17-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi18-after_doi18-warnings18-errors18-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi19-after_doi19-warnings19-errors19-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.008s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi20-after_doi20-warnings20-errors20-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi21-after_doi21-warnings21-errors21-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi22-after_doi22-warnings22-errors22-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi23-after_doi23-warnings23-errors23-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi24-after_doi24-warnings24-errors24-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi25-after_doi25-warnings25-errors25-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi26-after_doi26-warnings26-errors26-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi27-after_doi27-warnings27-errors27-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi28-after_doi28-warnings28-errors28-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi29-after_doi29-warnings29-errors29-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi30-after_doi30-warnings30-errors30-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi31-after_doi31-warnings31-errors31-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi32-after_doi32-warnings32-errors32-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[1-before_doi33-after_doi33-warnings33-errors33-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi34-after_doi34-warnings34-errors34-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi35-after_doi35-warnings35-errors35-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi36-after_doi36-warnings36-errors36-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.008s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi37-after_doi37-warnings37-errors37-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi38-after_doi38-warnings38-errors38-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi39-after_doi39-warnings39-errors39-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi40-after_doi40-warnings40-errors40-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi41-after_doi41-warnings41-errors41-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi42-after_doi42-warnings42-errors42-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi43-after_doi43-warnings43-errors43-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi44-after_doi44-warnings44-errors44-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi45-after_doi45-warnings45-errors45-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi46-after_doi46-warnings46-errors46-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi47-after_doi47-warnings47-errors47-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi48-after_doi48-warnings48-errors48-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi49-after_doi49-warnings49-errors49-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi50-after_doi50-warnings50-errors50-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi51-after_doi51-warnings51-errors51-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi52-after_doi52-warnings52-errors52-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi53-after_doi53-warnings53-errors53-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi54-after_doi54-warnings54-errors54-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi55-after_doi55-warnings55-errors55-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi56-after_doi56-warnings56-errors56-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi57-after_doi57-warnings57-errors57-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi58-after_doi58-warnings58-errors58-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi59-after_doi59-warnings59-errors59-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi60-after_doi60-warnings60-errors60-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi61-after_doi61-warnings61-errors61-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi62-after_doi62-warnings62-errors62-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi63-after_doi63-warnings63-errors63-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi64-after_doi64-warnings64-errors64-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi65-after_doi65-warnings65-errors65-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi66-after_doi66-warnings66-errors66-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[2-before_doi67-after_doi67-warnings67-errors67-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi68-after_doi68-warnings68-errors68-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi69-after_doi69-warnings69-errors69-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi70-after_doi70-warnings70-errors70-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi71-after_doi71-warnings71-errors71-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi72-after_doi72-warnings72-errors72-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi73-after_doi73-warnings73-errors73-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi74-after_doi74-warnings74-errors74-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi75-after_doi75-warnings75-errors75-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi76-after_doi76-warnings76-errors76-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi77-after_doi77-warnings77-errors77-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi78-after_doi78-warnings78-errors78-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi79-after_doi79-warnings79-errors79-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi80-after_doi80-warnings80-errors80-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi81-after_doi81-warnings81-errors81-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi82-after_doi82-warnings82-errors82-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi83-after_doi83-warnings83-errors83-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi84-after_doi84-warnings84-errors84-False-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi85-after_doi85-warnings85-errors85-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi86-after_doi86-warnings86-errors86-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi87-after_doi87-warnings87-errors87-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi88-after_doi88-warnings88-errors88-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi89-after_doi89-warnings89-errors89-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi90-after_doi90-warnings90-errors90-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi91-after_doi91-warnings91-errors91-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi92-after_doi92-warnings92-errors92-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.006s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi93-after_doi93-warnings93-errors93-True-False] _

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
identifier = <Identifier 1, Repository: Root Index>, indextree = None
location = <function location at 0x7fc0814abb70>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
db_oaischema = None

    @pytest.fixture()
    def doi_records(app, db, identifier, indextree, location, db_itemtype, db_oaischema):
        indexer = WekoIndexer()
        indexer.get_es_index()
        results = []
        with app.test_request_context():
            i = 1
            filename = "helloworld.pdf"
            mimetype = "application/pdf"
            filepath = "tests/data/helloworld.pdf"
            results.append(
>               make_record(db, indexer, i, filepath, filename, mimetype, "xyz.jalc")
            )

tests/conftest.py:2618: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:3798: in make_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.005s]
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi94-after_doi94-warnings94-errors94-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04c7137f0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04c71b388>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04c7136d8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04c713860>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04c7136d8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04c7136d8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04c713588>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi95-after_doi95-warnings95-errors95-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04c626748>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04c62b108>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04c6265f8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04c6267b8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04c6265f8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04c6265f8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04c626400>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi96-after_doi96-warnings96-errors96-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04bc847b8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04bc8a6c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04bc846a0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04bc847f0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04bc846a0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04bc846a0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04bc84588>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi97-after_doi97-warnings97-errors97-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04bf1aa90>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04bf1ed88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04bf1a978>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04bf1ab00>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04bf1a978>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04bf1a978>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04bf1a828>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi98-after_doi98-warnings98-errors98-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04b9154a8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04b910ec8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b915470>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b9152b0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b915470>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b915470>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04b915160>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi99-after_doi99-warnings99-errors99-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04b39f470>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04b3a53c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b3b1908>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b39f5f8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b3b1908>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b3b1908>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04b39f320>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi100-after_doi100-warnings100-errors100-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04b0665c0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04b062708>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b066588>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04b0663c8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b066588>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04b066588>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04b066278>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[3-before_doi101-after_doi101-warnings101-errors101-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04abbccc0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04abc2888>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04abbcba8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04abbcd30>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04abbcba8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04abbcba8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04abbca58>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi102-after_doi102-warnings102-errors102-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04a856cc0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04a863148>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04a856ba8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04a856d30>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04a856ba8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04a856ba8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04a856a58>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi103-after_doi103-warnings103-errors103-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04a3311d0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04a330848>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04a331198>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04a328b70>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04a331198>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04a331198>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04a328d30>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi104-after_doi104-warnings104-errors104-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc049ee57b8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc049ee6988>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc049ee56a0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049ee5828>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc049ee56a0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc049ee56a0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc049ee5550>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi105-after_doi105-warnings105-errors105-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0499b1a90>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0499b2e88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0499b1978>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0499b1b00>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0499b1978>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0499b1978>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0499b1828>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi106-after_doi106-warnings106-errors106-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0496a08d0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0495771c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0496a07b8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0496a0940>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0496a07b8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0496a07b8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0496a0668>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi107-after_doi107-warnings107-errors107-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc049297208>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc049297400>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc049294388>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0492973c8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049297208>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0492973c8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0492973c8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0492970b8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi108-after_doi108-warnings108-errors108-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc048cf2400>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc048ceec08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc048cf23c8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc048cf2208>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc048cf23c8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc048cf23c8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc048cf20b8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi109-after_doi109-warnings109-errors109-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc049d4c0b8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0498627c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc049d4c1d0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc049d4c048>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc049d4c1d0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc049d4c1d0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc049d4c320>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi110-after_doi110-warnings110-errors110-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0484d97f0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0484db348>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0484d96d8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0484d9860>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0484d96d8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0484d96d8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0484d9588>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi111-after_doi111-warnings111-errors111-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc048098b70>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04809bd08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc048098a58>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc048098be0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc048098a58>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc048098a58>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc048098908>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi112-after_doi112-warnings112-errors112-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc047bb7080>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc047bb3208>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047bb7048>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047ba9dd8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047bb7048>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047bb7048>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc047ba9be0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi113-after_doi113-warnings113-errors113-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc047866898>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc047866828>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc047867d88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047866710>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047866898>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047866710>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047866710>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0478665c0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi114-after_doi114-warnings114-errors114-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0472fd630>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc047306288>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0472fd518>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0472fd6a0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0472fd518>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0472fd518>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0472fd3c8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi115-after_doi115-warnings115-errors115-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc047004a20>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0470074c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047004908>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc047004a90>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047004908>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc047004908>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0470047b8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi116-after_doi116-warnings116-errors116-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc046a42828>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc046a45108>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc046a42710>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046a42898>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc046a42710>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc046a42710>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc046a425c0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi117-after_doi117-warnings117-errors117-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc046600ba8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc046603a88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc046600a90>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046600c18>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc046600a90>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc046600a90>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc046600940>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi118-after_doi118-warnings118-errors118-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04611d0b8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc046116fc8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04611d080>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc046112fd0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04611d080>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04611d080>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc046112c18>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi119-after_doi119-warnings119-errors119-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc045d0c860>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc045d11ac8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc045d0c748>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc045d0c8d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc045d0c748>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc045d0c748>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc045d0c5f8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi120-after_doi120-warnings120-errors120-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc045829668>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc045830088>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc045829550>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0458296d8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc045829550>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc045829550>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc045829400>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi121-after_doi121-warnings121-errors121-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0454f0a58>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0454f3148>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0454f0940>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0454f0ac8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0454f0940>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0454f0940>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0454f07f0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi122-after_doi122-warnings122-errors122-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc044fea860>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc044febe48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044fea748>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044fea8d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044fea748>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044fea748>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc044fea5f8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi123-after_doi123-warnings123-errors123-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc044e65550>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc044e62848>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044e65518>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044e65358>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044e65518>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044e65518>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc044e65208>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi124-after_doi124-warnings124-errors124-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc044977278>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc044977470>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc044974488>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044977438>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc044977278>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044977438>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc044977438>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc044977128>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi125-after_doi125-warnings125-errors125-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0443ad2b0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0443ae7c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0443ad278>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0443ad0b8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0443ad278>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0443ad278>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc044518d68>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi126-after_doi126-warnings126-errors126-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc04404c9b0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04404f988>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04404c898>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04404ca20>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04404c898>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc04404c898>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04404c748>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi127-after_doi127-warnings127-errors127-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc043aeb9b0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc043aed208>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043aeb898>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc043aeba20>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043aeb898>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043aeb898>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc043aeb748>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi128-after_doi128-warnings128-errors128-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc043638c88>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04363c948>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043638b70>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc043638cf8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043638b70>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043638b70>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc043638a20>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi129-after_doi129-warnings129-errors129-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0433366a0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc043330a48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043336668>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0433364a8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043336668>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc043336668>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc043336358>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi130-after_doi130-warnings130-errors130-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc042ec3780>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc042ec4f08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc042ec3668>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc042ec37f0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc042ec3668>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc042ec3668>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc042ec3518>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi131-after_doi131-warnings131-errors131-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc042a765c0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc042a89188>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc042a764a8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc042a76630>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc042a764a8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc042a764a8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc042a76358>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi132-after_doi132-warnings132-errors132-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0425690f0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc042660408>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0425690b8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc04265beb8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0425690b8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0425690b8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc04265bc50>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi133-after_doi133-warnings133-errors133-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0420c80f0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0420c0c88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0420c80b8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0420bbeb8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0420c80b8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0420c80b8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0420bbc50>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi134-after_doi134-warnings134-errors134-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc041dd43c8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc041dd93c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041dd4390>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041dd41d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041dd4390>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041dd4390>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc041dd4080>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[4-before_doi135-after_doi135-warnings135-errors135-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0418039b0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc041806508>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041803898>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041803a20>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041803898>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041803898>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc041803748>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi136-after_doi136-warnings136-errors136-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc041392c88>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0413979c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041392b70>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc041392cf8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041392b70>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc041392b70>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc041392a20>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi137-after_doi137-warnings137-errors137-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc040fc3ac8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc040fd3d88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040fc39b0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040fc3b38>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040fc39b0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040fc39b0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc040fc3860>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi138-after_doi138-warnings138-errors138-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc040d58358>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc040d50fc8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040d58320>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040d58160>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040d58320>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040d58320>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc040d4bfd0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi139-after_doi139-warnings139-errors139-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc040749940>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc040751148>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040749828>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0407499b0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040749828>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040749828>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0407496d8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi140-after_doi140-warnings140-errors140-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc040319c18>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc04031e5c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040319b00>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc040319c88>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040319b00>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc040319b00>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0403199b0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi141-after_doi141-warnings141-errors141-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03fe86a58>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03fe9b988>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03fe86940>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03fe86ac8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03fe86940>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03fe86940>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03fe867f0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi142-after_doi142-warnings142-errors142-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03fa3f588>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03fa3ba88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03fa3f550>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03fa3f390>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03fa3f550>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03fa3f550>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03fa3f240>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi143-after_doi143-warnings143-errors143-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03f919588>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03f91d388>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03f919550>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03f919390>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03f919550>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03f919550>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03f919240>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi144-after_doi144-warnings144-errors144-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03f266668>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03f267a48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03f266550>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03f2666d8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03f266550>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03f266550>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03f266400>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi145-after_doi145-warnings145-errors145-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03ee21080>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03ee1eb48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03ee21048>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03ee19dd8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03ee21048>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03ee21048>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03ee19be0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi146-after_doi146-warnings146-errors146-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03e8af358>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03e8b5088>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e8af320>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e8af160>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e8af320>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e8af320>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03e964fd0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi147-after_doi147-warnings147-errors147-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03e3ef198>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03e3f0408>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e3ef160>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e557f28>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e3ef160>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e3ef160>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03e557cf8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi148-after_doi148-warnings148-errors148-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03e10c898>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03e110588>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e10c780>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03e10c908>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e10c780>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03e10c780>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03e10c630>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi149-after_doi149-warnings149-errors149-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03dc69898>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03dc6adc8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03dc69780>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03dc69908>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03dc69780>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03dc69780>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03dc69630>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi150-after_doi150-warnings150-errors150-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03d774b70>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03d77c548>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03d774a58>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03d774be0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03d774a58>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03d774a58>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03d774908>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi151-after_doi151-warnings151-errors151-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03d4fa588>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03d4f4648>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03d4fa550>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03d4fa390>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03d4fa550>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03d4fa550>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03d4fa240>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi152-after_doi152-warnings152-errors152-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03ce81668>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03ce82b48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03ce81550>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03ce816d8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03ce81550>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03ce81550>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03ce81400>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi153-after_doi153-warnings153-errors153-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03c9c36a0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03c9bfec8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c9c3668>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c9c34a8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c9c3668>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c9c3668>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03c9c3358>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi154-after_doi154-warnings154-errors154-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03c89c550>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03c894d88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c89c518>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c89c358>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c89c518>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c89c518>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03c89c208>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi155-after_doi155-warnings155-errors155-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03c2665f8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03c16b148>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c2664e0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03c266668>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c2664e0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03c2664e0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03c266390>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi156-after_doi156-warnings156-errors156-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03bea5630>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03bea44c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03bea55f8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03bea5438>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03bea55f8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03bea55f8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03bea52e8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi157-after_doi157-warnings157-errors157-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03b9c0d30>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03b9c4648>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b9c0c18>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b9c0da0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b9c0c18>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b9c0c18>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03b9c0ac8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi158-after_doi158-warnings158-errors158-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03b699d30>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03b69dec8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b699c18>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b699da0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b699c18>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b699c18>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03b699ac8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi159-after_doi159-warnings159-errors159-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03b1af240>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03b1b0608>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b1af208>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03b1af048>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b1af208>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03b1af208>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03b266da0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi160-after_doi160-warnings160-errors160-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03af24828>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03ad69708>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03af24710>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03af24898>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03af24710>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03af24710>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03af245c0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi161-after_doi161-warnings161-errors161-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03a8f6b00>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03a8f7c08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a8f69e8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a8f6b70>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a8f69e8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a8f69e8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03a8f6898>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi162-after_doi162-warnings162-errors162-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03a422940>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03a3b4f88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a422828>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a4229b0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a422828>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a422828>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03a4226d8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi163-after_doi163-warnings163-errors163-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03a05d470>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03a05e108>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a05d438>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03a05d278>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a05d438>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03a05d438>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03a05d128>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi164-after_doi164-warnings164-errors164-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc039a37470>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc039a31948>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc039a37438>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc039a37278>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc039a37438>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc039a37438>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc039a37128>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi165-after_doi165-warnings165-errors165-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0396c9748>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0396cc108>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0396c9710>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0396c9550>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0396c9710>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0396c9710>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0396c9400>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi166-after_doi166-warnings166-errors166-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc039275d30>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03927f188>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc039275c18>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc039275da0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc039275c18>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc039275c18>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc039275ac8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi167-after_doi167-warnings167-errors167-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc038fcb240>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc038fcc688>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038fcb208>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc038fcb048>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038fcb208>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038fcb208>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc038fc2da0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi168-after_doi168-warnings168-errors168-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0388d2080>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0388c9a48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0388d2048>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0388b4dd8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0388d2048>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0388d2048>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0388b4be0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi169-after_doi169-warnings169-errors169-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc038627780>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0385aab88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038627668>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0386277f0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038627668>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038627668>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc038627518>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi170-after_doi170-warnings170-errors170-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc038106780>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03810b408>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038106668>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0381067f0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038106668>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc038106668>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc038106518>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi171-after_doi171-warnings171-errors171-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0379965c0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc037997448>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0379965f8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc037976c50>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0379965f8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0379965f8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc038049898>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi172-after_doi172-warnings172-errors172-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0379ab6a0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0379ad948>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0379ab588>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0379ab710>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0379ab588>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0379ab588>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0379ab438>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi173-after_doi173-warnings173-errors173-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc037428a20>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0374312c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc037428908>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc037428a90>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc037428908>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc037428908>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0374287b8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi174-after_doi174-warnings174-errors174-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03707acf8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03707e808>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03707abe0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03707ad68>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03707abe0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03707abe0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03707aa90>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi175-after_doi175-warnings175-errors175-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc036db36d8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc036db8388>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc036db35c0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc036db3748>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc036db35c0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc036db35c0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc036db3470>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi176-after_doi176-warnings176-errors176-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0368146d8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03680d848>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0368146a0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0368144e0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0368146a0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0368146a0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc036814390>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi177-after_doi177-warnings177-errors177-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0363d98d0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0363daa08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0363d97b8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0363d9940>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0363d97b8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0363d97b8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0363d9668>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi178-after_doi178-warnings178-errors178-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc035e946d8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc035e996c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc035e945c0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035e94748>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc035e945c0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc035e945c0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc035e94470>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi179-after_doi179-warnings179-errors179-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc035a94a58>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc035a9d048>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc035a94940>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035a94ac8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc035a94940>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc035a94940>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc035a947f0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi180-after_doi180-warnings180-errors180-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0355a2d30>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0355a7588>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0355a2c18>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0355a2da0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0355a2c18>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0355a2c18>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0355a2ac8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi181-after_doi181-warnings181-errors181-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc035262780>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc035262710>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0351a90c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0352625f8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc035262780>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0352625f8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0352625f8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0352624a8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[5-before_doi182-after_doi182-warnings182-errors182-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc034dc0710>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc034dbc5c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc034dc06d8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc034dc0518>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc034dc06d8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc034dc06d8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc034dc03c8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi183-after_doi183-warnings183-errors183-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03493f908>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0349417c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03493f7f0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03493f978>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03493f7f0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03493f7f0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03493f6a0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi184-after_doi184-warnings184-errors184-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03433d710>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc034341448>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03433d5f8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03433d780>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03433d5f8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03433d5f8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03433d4a8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi185-after_doi185-warnings185-errors185-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0340fba90>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0340ffdc8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0340fb978>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0340fbb00>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0340fb978>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0340fb978>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0340fb828>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi186-after_doi186-warnings186-errors186-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc033d4cd68>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc033d52308>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc033d4cc50>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc033d4cdd8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc033d4cc50>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc033d4cc50>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc033d4cb00>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi187-after_doi187-warnings187-errors187-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0336c7748>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0336c9e48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0336c7630>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0336c77b8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0336c7630>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0336c7630>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0336c74e0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi188-after_doi188-warnings188-errors188-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0334a5748>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0334a1308>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0334a5710>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0334a5550>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0334a5710>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0334a5710>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0334a5400>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi189-after_doi189-warnings189-errors189-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc033027940>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc032e2a588>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc033027828>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0330279b0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc033027828>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc033027828>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0330276d8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi190-after_doi190-warnings190-errors190-False-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc032d5d278>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc032d5b1c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc032d5d240>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc032d5d080>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc032d5d240>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc032d5d240>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc032d52cf8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi191-after_doi191-warnings191-errors191-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0326c6a20>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0326cbd08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0326c6908>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0326c6a90>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0326c6908>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0326c6908>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0326c67b8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi192-after_doi192-warnings192-errors192-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03231f828>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0323241c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03231f710>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03231f898>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03231f710>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03231f710>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03231f5c0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi193-after_doi193-warnings193-errors193-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc031ea9c18>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc031eae448>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031ea9b00>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc031ea9c88>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031ea9b00>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031ea9b00>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc031ea99b0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi194-after_doi194-warnings194-errors194-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc031aa6a20>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0319f1048>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031aa6908>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc031aa6a90>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031aa6908>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031aa6908>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc031aa67b8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi195-after_doi195-warnings195-errors195-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0316a4e48>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0315e99c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0316a4d30>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0316a4978>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0316a4d30>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0316a4d30>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0316a4b38>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi196-after_doi196-warnings196-errors196-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0311812b0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc03117bf08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031181278>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0311810b8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031181278>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc031181278>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc031176d68>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi197-after_doi197-warnings197-errors197-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc030f31a58>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc030f34a48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc030f31940>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc030f31ac8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc030f31940>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc030f31940>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc030f317f0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi198-after_doi198-warnings198-errors198-True-False] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc030986860>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc030987f48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc030986748>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0309868d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc030986748>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc030986748>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0309865f8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi199-after_doi199-warnings199-errors199-True-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0304d3c50>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0304dd188>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0304d3b38>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0304d3cc0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0304d3b38>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0304d3b38>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0304d39e8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi200-after_doi200-warnings200-errors200-True-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc03004da58>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc030051dc8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03004d940>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc03004dac8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03004d940>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc03004d940>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc03004d7f0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi201-after_doi201-warnings201-errors201-True-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02fa8fe48>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02fa95788>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02fa8fe10>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02fa8fda0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02fa8fe10>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02fa8fe10>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02fa8fb70>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item3[None-before_doi202-after_doi202-warnings202-errors202-True-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02f7692e8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02f866c48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f7692b0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f7690f0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f7692b0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f7692b0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02f85dcf8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________________ ERROR at setup of test_get_thumbnail_key ___________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02f29a6d8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02f2a0988>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f29add8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f29ada0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f29add8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f29add8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02f29a978>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________ ERROR at setup of test_handle_check_metadata_not_existed ___________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02e7fa5f8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02e7f9c48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02e7fa5c0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02e7fa400>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02e7fa5c0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02e7fa5c0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02e7fa2b0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
____________ ERROR at setup of test_handle_get_all_id_in_item_type _____________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02c5b8128>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02c5b6248>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02c5b80f0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02c621f98>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02c5b80f0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02c5b80f0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02c621c88>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
______________________ ERROR at setup of test_export_all _______________________

db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
instance_path = '/var/tmp/tmpbe8y4ca5'
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]

    @pytest.fixture()
    def db_records2(db, instance_path, users):
        with db.session.begin_nested():
            Location.query.delete()
            loc = Location(name="local", uri=instance_path, default=True)
            db.session.add(loc)
        db.session.commit()
    
        record_data = json_data("data/test_records.json")
        item_data = json_data("data/test_items.json")
        record_num = len(record_data)
        result = []
        with db.session.begin_nested():
            for d in range(record_num):
>               result.append(create_record(record_data[d], item_data[d]))

tests/conftest.py:1165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/helpers.py:49: in create_record
    record = WekoRecord.create(record_data, id_=rec_uuid)
../invenio-records/invenio_records/api.py:177: in create
    record=record
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in send
    for receiver in self.receivers_for(sender)]
.tox/c1/lib/python3.6/site-packages/blinker/base.py:267: in <listcomp>
    for receiver in self.receivers_for(sender)]
../invenio-oaiserver/invenio_oaiserver/receivers.py:28: in __call__
    new_sets = set(get_record_sets(record=record))
../invenio-oaiserver/invenio_oaiserver/percolator.py:137: in get_record_sets
    _create_percolator_mapping(index, percolator_doc_type)
../invenio-oaiserver/invenio_oaiserver/percolator.py:37: in _create_percolator_mapping
    body=PERCOLATOR_MAPPING, ignore=[400, 404])
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:271: in put_mapping
    '_mapping', doc_type), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_mapping/item-v1.0.0 [status:403 request:0.007s]
____________________ ERROR at setup of test_delete_exported ____________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02d6359b0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02da4ea48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02d635278>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02d6351d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02d635278>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02d635278>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02d635470>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________________ ERROR at setup of test_cancel_export_all ___________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02eecd5f8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02ddecf48>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02eecd7f0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02eecd8d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02eecd7f0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02eecd7f0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02eecd278>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________________ ERROR at setup of test_get_export_status ___________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02f0eff60>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02e2fb108>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f0ef0b8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02f0ef080>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f0ef0b8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02f0ef0b8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02e31d898>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
______________ ERROR at setup of test_handle_check_item_is_locked ______________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0691f9668>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc069218388>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0691f9630>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0691f9470>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0691f9630>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0691f9630>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0691f9320>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_______________ ERROR at setup of test_handle_remove_es_metadata _______________

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def es(app):
        """Elasticsearch fixture."""
        try:
>           list(current_search.create())

tests/conftest.py:2757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:282: in create
    for result in _create(self.active_aliases):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:265: in _create
    for result in _create(value, alias=name):
.tox/c1/lib/python3.6/site-packages/invenio_search/ext.py:272: in _create
    ignore=ignore,
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/indices.py:91: in create
    params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 403
raw_data = '{"error":{"root_cause":[{"type":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow...":"cluster_block_exception","reason":"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];"},"status":403}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.AuthorizationException: TransportError(403, 'cluster_block_exception', 'blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: AuthorizationException
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-marc21-authority-ad-v1.0.0 [status:403 request:0.009s]
____________ ERROR at setup of test_check_index_access_permissions _____________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02bb09fd0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02bb17048>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02bb09f98>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02bb09ef0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02bb09f98>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02bb09f98>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02bb09cf8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_function_issue34520[1-before_doi0-after_doi0-warnings0-errors0-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02936ec18>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc029378408>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02936eb00>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02936ec88>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02936eb00>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02936eb00>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02936e9b0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
__________________ ERROR at setup of test_function_issue34535 __________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0291fca58>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0291ffa08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0291fcba8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0291fc5c0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0291fcba8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0291fcba8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0291fc748>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
__________________ ERROR at setup of test_function_issue34958 __________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc028ede128>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc028ee01c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc028ede0f0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc028ed4dd8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc028ede0f0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc028ede0f0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc028ed4c88>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item_issue34520[1-before_doi0-after_doi0-warnings0-errors0-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0286f15f8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0286f4088>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0286f15c0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0286f1400>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0286f15c0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0286f15c0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0286f12b0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_fill_system_item_issue34520[1000-before_doi1-after_doi1-warnings1-errors1-True] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc028411400>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0284115f8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02840b8c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0284115c0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc028411400>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0284115c0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0284115c0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0284112b0>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_check_exist_record_issue35315[1-http://TEST_SERVER/records/1-warnings0-errors0-keep] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02801a6d8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc028019fc8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02801a5c0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02801a748>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02801a5c0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02801a5c0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02801a470>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_check_exist_record_issue35315[1000-http://TEST_SERVER/records/1-warnings1-errors1-None] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc027a560f0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc027a5b0c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc027a560b8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc027a4deb8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc027a560b8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc027a560b8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc027a4dc50>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_check_exist_record_issue35315[1000-http://TEST_SERVER/records/1000-warnings2-errors2-None] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0275a93c8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc027667608>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0275a9390>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc0275a91d0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0275a9390>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0275a9390>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0275a9080>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_ ERROR at setup of test_handle_check_exist_record_issue35315[None-None-warnings3-errors3-new] _

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc027226208>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc027222988>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0272261d0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02720deb8>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0272261d0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0272261d0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02720dd68>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
________________________ ERROR at setup of test_search _________________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc026dbf5c0>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc026dc4e88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026dbfcc0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026dbfc88>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026dbfcc0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026dbfcc0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc026dbf860>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________________ ERROR at setup of test_search_acl_guest ____________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc026923588>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc0268a96c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026923c88>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026923c50>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026923c88>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026923c88>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc026923828>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________________ ERROR at setup of test_search_acl[3-200] ___________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc026430860>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc026435d88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026430f60>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc026430f28>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026430f60>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc026430f60>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc026430b00>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
________________ ERROR at setup of test_opensearch_description _________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc0277f9588>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc027b20408>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0277f99b0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc027e044e0>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0277f99b0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc0277f99b0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc027e043c8>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________ ERROR at setup of test_opensearch_description_acl_guest ____________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02b713400>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc029aaa248>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02b713668>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02b713f60>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02b713668>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02b713668>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02b5b8898>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
____________________ ERROR at setup of test_journal_detail _____________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc029f52c50>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc029b12d08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc029f52b70>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc029f52b38>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc029f52b70>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc029f52b70>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc029f52588>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_______________ ERROR at setup of test_search_feedback_mail_list _______________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc029d07a90>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02a459708>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc029d07cc0>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc029d07b38>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc029d07cc0>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc029d07cc0>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc029d07978>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
____________________ ERROR at setup of test_get_child_list _____________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02a688ac8>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02acec9c8>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02a688dd8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02a688898>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02a688dd8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02a688dd8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02a688048>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
__________________ ERROR at setup of test_get_path_name_dict ___________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc02a330390>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc02a34bd08>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02a3302e8>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc02a330278>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02a3302e8>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc02a3302e8>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc02a330630>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
_____________________ ERROR at setup of test_gettitlefacet _____________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc025b6b860>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc025b70b88>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc025b6bf60>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc025b6bf28>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc025b6bf60>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc025b6bf60>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc025b6bb00>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
___________________ ERROR at setup of test_get_last_item_id ____________________

self = Engine(postgresql+psycopg2://invenio:***@postgresql:5432/postgres)
fn = <bound method Pool.connect of <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>>
connection = None

    def _wrap_pool_connect(self, fn, connection):
        dialect = self.dialect
        try:
>           return fn()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>

    def connect(self):
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
        if not self._use_threadlocal:
>           return _ConnectionFairy._checkout(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionFairy'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>, threadconns = None
fairy = None

    @classmethod
    def _checkout(cls, pool, threadconns=None, fairy=None):
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool._ConnectionRecord'>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>

    @classmethod
    def checkout(cls, pool):
>       rec = pool._do_get()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
                with util.safe_reraise():
>                   self._dec_overflow()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fc025775898>
type_ = None, value = None, traceback = None

    def __exit__(self, type_, value, traceback):
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            self._exc_info = None  # remove potential circular references
            if not self.warn_only:
>               compat.reraise(exc_type, exc_value, exc_tb)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'psycopg2.OperationalError'>
value = OperationalError('FATAL:  sorry, too many clients already\n',)
tb = <traceback object at 0x7fc025782408>, cause = None

    def reraise(tp, value, tb=None, cause=None):
        if cause is not None:
            assert cause is not value, "Same cause emitted"
            value.__cause__ = cause
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
>       raise value

.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>

    def _do_get(self):
        use_overflow = self._max_overflow > -1
    
        try:
            wait = use_overflow and self._overflow >= self._max_overflow
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %d"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>

    def _create_connection(self):
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc025775f98>
pool = <sqlalchemy.pool.QueuePool object at 0x7fc025775f60>, connect = True

    def __init__(self, pool, connect=True):
        self.__pool = pool
        if connect:
>           self.__connect(first_connect_check=True)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool._ConnectionRecord object at 0x7fc025775f98>
first_connect_check = True

    def __connect(self, first_connect_check=False):
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.connection = None
        try:
            self.starttime = time.time()
>           connection = pool._invoke_creator(self)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool._ConnectionRecord object at 0x7fc025775f98>

    def connect(connection_record=None):
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = fn(
                    dialect, connection_record, cargs, cparams
                )
                if connection is not None:
                    return connection
>       return dialect.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc025775b38>
cargs = ()
cparams = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
>       return self.dbapi.connect(*cargs, **cparams)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       psycopg2.OperationalError: FATAL:  sorry, too many clients already

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    @pytest.yield_fixture()
    def db(app):
        """Get setup database."""
>       if not database_exists(str(db_.engine.url)):

tests/conftest.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:484: in database_exists
    return bool(get_scalar_result(engine, text))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/functions/database.py:458: in get_scalar_result
    result_proxy = engine.execute(sql)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2143: in execute
    connection = self.contextual_connect(close_with_result=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2192: in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2232: in _wrap_pool_connect
    e, dialect, self
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1528: in _handle_dbapi_exception_noconnection
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:2228: in _wrap_pool_connect
    return fn()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:434: in connect
    return _ConnectionFairy._checkout(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:831: in _checkout
    fairy = _ConnectionRecord.checkout(pool)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:563: in checkout
    rec = pool._do_get()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1259: in _do_get
    self._dec_overflow()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py:67: in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:277: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:1256: in _do_get
    return self._create_connection()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:379: in _create_connection
    return _ConnectionRecord(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:508: in __init__
    self.__connect(first_connect_check=True)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/pool.py:710: in __connect
    connection = pool._invoke_creator(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py:114: in connect
    return dialect.connect(*cargs, **cparams)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:437: in connect
    return self.dbapi.connect(*cargs, **cparams)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = 'host=postgresql user=invenio password=dbpass123 port=5432 dbname=postgres'
connection_factory = None, cursor_factory = None
kwargs = {'database': 'postgres', 'host': 'postgresql', 'password': 'dbpass123', 'port': 5432, ...}
kwasync = {}

    def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
        """
        Create a new database connection.
    
        The connection parameters can be specified as a string:
    
            conn = psycopg2.connect("dbname=test user=postgres password=secret")
    
        or using a set of keyword arguments:
    
            conn = psycopg2.connect(database="test", user="postgres", password="secret")
    
        Or as a mix of both. The basic connection parameters are:
    
        - *dbname*: the database name
        - *database*: the database name (only as keyword argument)
        - *user*: user name used to authenticate
        - *password*: password used to authenticate
        - *host*: database host address (defaults to UNIX socket if not provided)
        - *port*: connection port number (defaults to 5432 if not provided)
    
        Using the *connection_factory* parameter a different class or connections
        factory can be specified. It should be a callable object taking a dsn
        argument.
    
        Using the *cursor_factory* parameter, a new default cursor factory will be
        used by cursor().
    
        Using *async*=True an asynchronous connection will be created. *async_* is
        a valid alias (for Python versions where ``async`` is a keyword).
    
        Any other keyword parameter will be passed to the underlying client
        library: the list of supported parameters depends on the library version.
    
        """
        kwasync = {}
        if 'async' in kwargs:
            kwasync['async'] = kwargs.pop('async')
        if 'async_' in kwargs:
            kwasync['async_'] = kwargs.pop('async_')
    
        if dsn is None and not kwargs:
            raise TypeError('missing dsn and no parameters')
    
        dsn = _ext.make_dsn(dsn, **kwargs)
>       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
E       sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already
E        (Background on this error at: http://sqlalche.me/e/e3q8)

.tox/c1/lib/python3.6/site-packages/psycopg2/__init__.py:130: OperationalError
=================================== FAILURES ===================================
_________________ TestItemManagementBulkSearch.test_index_acl __________________

self = <tests.test_admin.TestItemManagementBulkSearch object at 0x7fc07d9a7550>
client = <FlaskClient <Flask 'testapp'>>
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]
db_records2 = [(<PersistentIdentifier depid:1 / rec:acca89f1-9dd9-4d36-8087-c8fc2ab201d8 (R)>, <PersistentIdentifier recid:1 / rec:a...617258105262': {'resourceuri': 'http://purl.org/coar/resource_type/c_5794', 'resourcetype': 'conference paper'}}), ...]

    def test_index_acl(self,client, users, db_records2):
        user = users[3]['obj']
        assert user.roles[0].name=='System Administrator'
    
        url = url_for("items/search.index", _external=True)
        with patch("flask.templating._render", return_value=""):
            res = client.get(url)
            assert res.status == '302 FOUND'
    
        with patch("flask_login.utils._get_user", return_value=user):
            with patch("flask.templating._render", return_value=""):
                res = client.get(url)
>               assert res.status == '200 OK'
E               AssertionError: assert '500 INTERNAL SERVER ERROR' == '200 OK'
E                 - 200 OK
E                 + 500 INTERNAL SERVER ERROR

tests/test_admin.py:113: AssertionError
__________________________ test_ItemImportView_check ___________________________

request = <Request 'http://TEST_SERVER/' [POST]>, csrf_header = 'X-CSRFToken'

    def validate_csrf_header(request,csrf_header="X-CSRFToken"):
        """Validate CSRF header
    
        Args:
            csrf_header (str, optional): CSRF Token Header. Defaults to "X-CSRFToken".
    
        Raises:
            CSRFError: _description_
            CSRFError: _description_
            CSRFError: _description_
        """
        try:
            csrf_token = request.headers.get(csrf_header)
>           validate_csrf(csrf_token)

../weko-admin/weko_admin/api.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data = None, secret_key = 'SECRET_KEY', time_limit = 3600, token_key = None

    def validate_csrf(data, secret_key=None, time_limit=None, token_key=None):
        """Check if the given data is a valid CSRF token. This compares the given
        signed token to the one stored in the session.
    
        :param data: The signed CSRF token to be checked.
        :param secret_key: Used to securely sign the token. Default is
            ``WTF_CSRF_SECRET_KEY`` or ``SECRET_KEY``.
        :param time_limit: Number of seconds that the token is valid. Default is
            ``WTF_CSRF_TIME_LIMIT`` or 3600 seconds (60 minutes).
        :param token_key: Key where token is stored in session for comparision.
            Default is ``WTF_CSRF_FIELD_NAME`` or ``'csrf_token'``.
    
        :raises ValidationError: Contains the reason that validation failed.
    
        .. versionchanged:: 0.14
            Raises ``ValidationError`` with a specific error message rather than
            returning ``True`` or ``False``.
        """
    
        secret_key = _get_config(
            secret_key, 'WTF_CSRF_SECRET_KEY', current_app.secret_key,
            message='A secret key is required to use CSRF.'
        )
        field_name = _get_config(
            token_key, 'WTF_CSRF_FIELD_NAME', 'csrf_token',
            message='A field name is required to use CSRF.'
        )
        time_limit = _get_config(
            time_limit, 'WTF_CSRF_TIME_LIMIT', 3600, required=False
        )
    
        if not data:
>           raise ValidationError('The CSRF token is missing.')
E           wtforms.validators.ValidationError: The CSRF token is missing.

.tox/c1/lib/python3.6/site-packages/flask_wtf/csrf.py:91: ValidationError

During handling of the above exception, another exception occurred:

i18n_app = <Flask 'testapp'>
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]
client = <FlaskClient <Flask 'testapp'>>
client_request_args = <Response streamed [200 OK]>

    def test_ItemImportView_check(i18n_app, users, client,client_request_args):
        file_path = os.path.join(
            os.path.dirname(os.path.abspath(__file__)),
            'data',
            'sample_file',
            'sample_csv.csv'
        )
    
        csv_data = open(file_path, "rb")
        data = {"file": (csv_data, "sample_csv.csv")}
    
        client.post(
            "/",
            data=data,
            buffered=True,
            content_type="multipart/form-data",
        )
    
        rf = request.form.to_dict()
        rf['username'] = "test_user"
    
        # mimetype = 'application/json'
        # headers = {
        #     'Content-Type': mimetype,
        #     'Accept': mimetype
        # }
        # data = {
        #     'Data': [20.0, 30.0, 401.0, 50.0],
        #     'Date': ['2017-08-11', '2017-08-12', '2017-08-13', '2017-08-14'],
        #     'Day': 4
        # }
    
        # client.post(
        #     '/',
        #     data=json.dumps(data),
        #     headers=headers
        # )
    
        with patch("flask_login.utils._get_user", return_value=users[3]['obj']):
            test = ItemImportView()
            task = MagicMock()
            task.task_id = 1
            with patch("weko_search_ui.tasks.check_import_items_task.apply_async",return_Value=task):
>               assert test.check()

tests/test_admin.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/flask_admin/base.py:69: in inner
    return self._run_view(f, *args, **kwargs)
.tox/c1/lib/python3.6/site-packages/flask_admin/base.py:368: in _run_view
    return fn(self, *args, **kwargs)
weko_search_ui/admin.py:338: in check
    validate_csrf_header(request)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <Request 'http://TEST_SERVER/' [POST]>, csrf_header = 'X-CSRFToken'

    def validate_csrf_header(request,csrf_header="X-CSRFToken"):
        """Validate CSRF header
    
        Args:
            csrf_header (str, optional): CSRF Token Header. Defaults to "X-CSRFToken".
    
        Raises:
            CSRFError: _description_
            CSRFError: _description_
            CSRFError: _description_
        """
        try:
            csrf_token = request.headers.get(csrf_header)
            validate_csrf(csrf_token)
        except ValidationError as e:
>           raise CSRFError(e.args[0])
E           flask_wtf.csrf.CSRFError: 400 Bad Request: The CSRF token is missing.

../weko-admin/weko_admin/api.py:231: CSRFError
------------------------------ Captured log setup ------------------------------
ERROR    flask.app:receivers.py:39 Error building event
Traceback (most recent call last):
  File "/code/modules/invenio-stats/invenio_stats/receivers.py", line 31, in __call__
    if self.name in current_stats.events:
  File "/code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/werkzeug/local.py", line 348, in __getattr__
    return getattr(self._get_current_object(), name)
  File "/code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/werkzeug/utils.py", line 91, in __get__
    value = self.func(obj)
  File "/code/modules/invenio-stats/invenio_stats/ext.py", line 79, in events
    queue = current_queues.queues[
  File "/code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/werkzeug/local.py", line 348, in __getattr__
    return getattr(self._get_current_object(), name)
AttributeError: 'int' object has no attribute 'queues'
_________________ TestItemBulkExport.test_check_export_status __________________

self = <tests.test_admin.TestItemBulkExport object at 0x7fc07b223b70>
app = <Flask 'testapp'>, client = <FlaskClient <Flask 'testapp'>>
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]
redis_connect = <simplekv.memory.redisstore.RedisStore object at 0x7fc07d12cef0>
mocker = <pytest_mock.plugin.MockerFixture object at 0x7fc07d12c8d0>

    def test_check_export_status(self,app,client,users, redis_connect,mocker):
    
        mocker.patch("weko_search_ui.utils.AsyncResult",side_effect=MockAsyncResult)
        mocker.patch("weko_search_ui.admin.check_celery_is_run",return_value=True)
        with patch("flask_login.utils._get_user", return_value=users[3]["obj"]):
            cache_key = app.config["WEKO_ADMIN_CACHE_PREFIX"].format(
                name="KEY_EXPORT_ALL", user_id=current_user.get_id()
            )
            datastore = redis_connect
            datastore.put(cache_key, "SUCCESS_task".encode("utf-8"), ttl_secs=30)
    
            url = url_for("items/bulk-export.check_export_status")
    
            res = client.get(url)
>           assert json.loads(res.data) == {'data': {
                'celery_is_run': True,
                'error_message': None,
                'export_run_msg': None,
                'export_status': False,
                'status': 'SUCCESS',
                'uri_status': False}}
E           AssertionError: assert {'data': {'ce...: False, ...}} == {'data': {'ce...: False, ...}}
E             Differing items:
E             {'data': {'celery_is_run': True, 'error_message': '', 'export_run_msg': None, 'export_status': False, ...}} != {'data': {'celery_is_run': True, 'error_message': None, 'export_run_msg': None, 'export_status': False, ...}}
E             Full diff:
E               {
E                'data': {'celery_is_run': True,
E             -           'error_message': None,
E             ?                            ^^^^...
E             
E             ...Full output truncated (8 lines hidden), use '-vv' to show

tests/test_admin.py:307: AssertionError
________________________ test_item_path_search_factory _________________________

app = <Flask 'testapp'>
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]
indices = {'index_dict': {'biblio_flag': False, 'browsing_group': '', 'browsing_role': 'Contributor', 'comment': '', ...}, 'index_non_dict': <Index 33>, 'index_non_dict_child': <Index 44>}

    def test_item_path_search_factory(app, users, indices):
        search = RecordsSearch()
        app.config['WEKO_SEARCH_TYPE_INDEX'] = 'index'
        app.config['OAISERVER_ES_MAX_CLAUSE_COUNT'] = 1
        app.config['WEKO_ADMIN_MANAGEMENT_OPTIONS'] = WEKO_ADMIN_MANAGEMENT_OPTIONS
        with app.test_request_context():
            with patch("flask_login.utils._get_user", return_value=users[3]['obj']):
                with patch("weko_search_ui.query.get_item_type_aggs", return_value={}):
                    mock_searchperm = MagicMock(side_effect=MockSearchPerm)
                    with patch('weko_search_ui.query.search_permission', mock_searchperm):
                        res = item_path_search_factory(self=None, search=search, index_id=33)
                        assert res
                        _rv = ([Bool(must=[Terms(path=[])], should=[Match(weko_creator_id='5'), Match(weko_shared_id='5'), Bool(must=[Match(publish_status='0'), Range(publish_date={'lte': 'now/d'})])]), Bool(must=[Match(relation_version_is_last='true')])], ['3', '4', '5'])
                        with patch('weko_search_ui.query.get_permission_filter', return_value=_rv):
                            res = item_path_search_factory(self=None, search=search, index_id=None)
                            assert res
        with patch("flask_login.utils._get_user",return_value=users[3]["obj"]):
            url = "/test?page=1&size=20&sort=controlnumber&search_type=2&q=3"
            with app.test_request_context(url):
                mock_searchperm = MagicMock(side_effect=MockSearchPerm)
                with patch("weko_search_ui.query.search_permission",mock_searchperm):
                    with patch("weko_search_ui.query.get_item_type_aggs",return_value={}):
                        # len(child_list) <= 1000
                        child_list = [str(i) for i in range(500)]
                        with patch("weko_search_ui.query.Indexes.get_child_list_recursive",return_value=child_list):
                            res = item_path_search_factory(self=None,search=search,index_id=33)
>                           assert json.dumps((res[0].query()).to_dict()) == '{"query": {"bool": {"must": [{"match": {"relation_version_is_last": "true"}}, {"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}]}}, {"match_all": {}}]}}, "post_filter": {"bool": {"must": [{"terms": {"path": ["33"]}}, {"bool": {"should": [{"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}, {"match": {"weko_creator_id": "5"}}]}}, {"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}, {"match": {"weko_shared_id": "5"}}]}}, {"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}, {"range": {"publish_date": {"lte": "now/d", "time_zone": "UTC"}}}]}}]}}]}}, "aggs": {"path": {"terms": {"field": "path", "include": "0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175|176|177|178|179|180|181|182|183|184|185|186|187|188|189|190|191|192|193|194|195|196|197|198|199|200|201|202|203|204|205|206|207|208|209|210|211|212|213|214|215|216|217|218|219|220|221|222|223|224|225|226|227|228|229|230|231|232|233|234|235|236|237|238|239|240|241|242|243|244|245|246|247|248|249|250|251|252|253|254|255|256|257|258|259|260|261|262|263|264|265|266|267|268|269|270|271|272|273|274|275|276|277|278|279|280|281|282|283|284|285|286|287|288|289|290|291|292|293|294|295|296|297|298|299|300|301|302|303|304|305|306|307|308|309|310|311|312|313|314|315|316|317|318|319|320|321|322|323|324|325|326|327|328|329|330|331|332|333|334|335|336|337|338|339|340|341|342|343|344|345|346|347|348|349|350|351|352|353|354|355|356|357|358|359|360|361|362|363|364|365|366|367|368|369|370|371|372|373|374|375|376|377|378|379|380|381|382|383|384|385|386|387|388|389|390|391|392|393|394|395|396|397|398|399|400|401|402|403|404|405|406|407|408|409|410|411|412|413|414|415|416|417|418|419|420|421|422|423|424|425|426|427|428|429|430|431|432|433|434|435|436|437|438|439|440|441|442|443|444|445|446|447|448|449|450|451|452|453|454|455|456|457|458|459|460|461|462|463|464|465|466|467|468|469|470|471|472|473|474|475|476|477|478|479|480|481|482|483|484|485|486|487|488|489|490|491|492|493|494|495|496|497|498|499", "size": "2"}, "aggs": {"date_range": {"filter": {"match": {"publish_status": "0"}}, "aggs": {"available": {"range": {"field": "publish_date", "ranges": [{"from": "now+1d/d"}, {"to": "now+1d/d"}]}}}}, "no_available": {"filter": {"bool": {"must_not": [{"match": {"publish_status": "0"}}]}}}}}}, "sort": [{"null": {"order": "asc", "unmapped_type": "long"}}, {"null": {"order": "asc", "unmapped_type": "long"}}, {"null": {"order": "asc", "unmapped_type": "long"}}], "_source": {"excludes": ["content"]}}'
E                           assert '{"query": {"...["content"]}}' == '{"query": {"...["content"]}}'
E                             - {"query": {"bool": {"must": [{"match": {"relation_version_is_last": "true"}}, {"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}]}}, {"match_all": {}}]}}, "post_filter": {"bool": {"must": [{"terms": {"path": ["33"]}}, {"bool": {"should": [{"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}, {"match": {"weko_creator_id": "5"}}]}}, {"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}, {"match": {"weko_shared_id": "5"}}]}}, {"bool": {"must": [{"terms": {"publish_status": ["0", "1"]}}, {"range": {"publish_date": {"lte": "now/d", "time_zone": "UT...
E                             
E                             ...Full output truncated (2 lines hidden), use '-vv' to show

tests/test_query.py:199: AssertionError
___________________________ test_function_issue35902 ___________________________

app = <Flask 'testapp'>
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]
communities = <Community, ID: comm1>
mocker = <pytest_mock.plugin.MockerFixture object at 0x7fc078a96550>

    def test_function_issue35902(app, users, communities, mocker):
        with app.test_client() as client:
            login_user_via_session(client, email=users[3]["email"])
            search = RecordsSearch()
            app.config['WEKO_SEARCH_KEYWORDS_DICT'] = WEKO_SEARCH_KEYWORDS_DICT
            app.config['WEKO_ADMIN_MANAGEMENT_OPTIONS'] = WEKO_ADMIN_MANAGEMENT_OPTIONS
            mocker.patch("weko_search_ui.query.search_permission",side_effect=MockSearchPerm)
            mocker.patch("weko_search_ui.permissions.search_permission",side_effect=MockSearchPerm)
            test = [
                {"bool":{"should":[{"match":{"weko_creator_id":None}},{"match":{"weko_shared_id":None}},{"bool":{"must":[{"match":{"publish_status":"0"}},{"range":{"publish_date":{"lte":"now/d","time_zone":"UTC"}}}]}}],"must":[{"terms":{"path":[]}}]}},
                {"bool":{"must":[{"match":{"relation_version_is_last":"true"}}]}},
            ]
            # not exist community
            # full text, detail search
            data = {
                "page":"1","size":"20","sort":"-createdate","creator":"","subject":"","sbjscheme":"","id":"","id_attr":"","type":"","itemtype":"","lang":"",
                "search_type":"0",
                "q":"test_data",
                "title":"aaa",
            }
            with app.test_request_context(headers=[("Accept-Language","en")],data=data):
                app.extensions['invenio-oauth2server'] = 1
                app.extensions['invenio-queues'] = 1
                test1 = copy.deepcopy(test)
                test1.append(
                    {"multi_match":{"query":"aaa","type":"most_fields","minimum_should_match":"75%","operator":"and","fields":["search_title","search_title.ja"]}}
                )
                test1.append(
                    {"bool":{"should":[
                        {"nested":{"query":{"multi_match":{"query":"test_data","operator":"and","fields":["content.attachment.content"]}},"path":"content"}},
                        {"query_string":{"query":"test_data","default_operator":"and","fields":["search_*","search_*.ja"]}}
                    ]}}
                )
                res,urlkwargs = default_search_factory(self=None, search=search)
                result = (res.query()).to_dict()
                result = result["query"]["bool"]["filter"][0]["bool"]["must"]
>               assert result == test1
E               AssertionError: assert [{'bool': {'m...st_data'}}]}}] == [{'bool': {'m...st_data'}}]}}]
E                 At index 0 diff: {'bool': {'should': [{'bool': {'must': [{'terms': {'publish_status': ['0', '1']}}, {'match': {'weko_creator_id': None}}]}}, {'bool': {'must': [{'terms': {'publish_status': ['0', '1']}}, {'match': {'weko_shared_id': None}}]}}, {'bool': {'must': [{'terms': {'publish_status': ['0']}}, {'range': {'publish_date': {'lte': 'now/d', 'time_zone': 'UTC'}}}]}}], 'must': [{'terms': {'path': []}}]}} != {'bool': {'should': [{'match': {'weko_creator_id': None}}, {'match': {'weko_shared_id': None}}, {'bool': {'must': [{'match': {'publish_status': '0'}}, {'range': {'pub...
E                 
E                 ...Full output truncated (35 lines hidden), use '-vv' to show

tests/test_query.py:286: AssertionError
____________________ test_IndexSearchResource_get_Exception ____________________

client_rest = <FlaskClient <Flask 'testapp'>>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]
item_type = [{'type': 'object', '$schema': 'http://json-schema.org/draft-04/schema#', 'required': ['pubdate', 'item_1617186331708'...type': 'string', 'title': 'SYSTEMIDT Identifier Type', 'format': 'select'}}, 'system_prop': True}}, 'description': ''}]
db_records = [(<PersistentIdentifier depid:1 / rec:0efbb202-5e09-41f8-9812-7d7c195a12e7 (R)>, <PersistentIdentifier recid:1 / rec:0...617258105262': {'resourceuri': 'http://purl.org/coar/resource_type/c_5794', 'resourcetype': 'conference paper'}}), ...]
facet_search_setting = None

    def test_IndexSearchResource_get_Exception(client_rest, db, users, item_type, db_records, facet_search_setting):
        sname = current_app.config["SERVER_NAME"]
        #from weko_index_tree.models import Index
        #datas = json_data("data/index.json")
        #indexes = list()
        #for index in datas:
        #    indexes.append(Index(**datas[index]))
        #with db.session.begin_nested():
        #    db.session.add_all(indexes)
        #db.session.commit()
    
        def dummy_response(data):
            if isinstance(data, str):
                data = json_data(data)
            dummy=response.Response(Search(), data)
            return dummy
        facet = json_data("data/search/facet.json")
        links = {"self":"?page=1&size=20"}
        for l in links:
            links[l]="http://"+sname+"/index/"+links[l]
        with patch("weko_admin.utils.get_facet_search_query", return_value=facet):
            with patch("weko_search_ui.rest.Indexes.get_self_list",side_effect=mock_path(**path1)):
                with patch("invenio_search.api.RecordsSearch.execute", return_value=dummy_response("data/search/execute_result01_02_03.json")):
                    with patch("weko_search_ui.rest.get_heading_info", side_effect=Exception):
>                       res = client_rest.get(url("/index/",{"self":"?page=1&size=20"}))

tests/test_rest.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/werkzeug/test.py:1029: in get
    return self.open(*args, **kw)
.tox/c1/lib/python3.6/site-packages/flask/testing.py:196: in open
    follow_redirects=follow_redirects
.tox/c1/lib/python3.6/site-packages/werkzeug/test.py:993: in open
    response = self.run_wsgi_app(environ.copy(), buffered=buffered)
.tox/c1/lib/python3.6/site-packages/werkzeug/test.py:884: in run_wsgi_app
    rv = run_wsgi_app(self.application, environ, buffered=buffered)
.tox/c1/lib/python3.6/site-packages/werkzeug/test.py:1119: in run_wsgi_app
    app_rv = app(environ, start_response)
.tox/c1/lib/python3.6/site-packages/flask/app.py:2334: in __call__
    return self.wsgi_app(environ, start_response)
.tox/c1/lib/python3.6/site-packages/flask/app.py:2320: in wsgi_app
    response = self.handle_exception(e)
.tox/c1/lib/python3.6/site-packages/flask/app.py:1766: in handle_exception
    reraise(exc_type, exc_value, tb)
.tox/c1/lib/python3.6/site-packages/flask/_compat.py:36: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/flask/app.py:2317: in wsgi_app
    response = self.full_dispatch_request()
.tox/c1/lib/python3.6/site-packages/flask/app.py:1840: in full_dispatch_request
    rv = self.handle_user_exception(e)
.tox/c1/lib/python3.6/site-packages/flask/app.py:1743: in handle_user_exception
    reraise(exc_type, exc_value, tb)
.tox/c1/lib/python3.6/site-packages/flask/_compat.py:36: in reraise
    raise value
.tox/c1/lib/python3.6/site-packages/flask/app.py:1838: in full_dispatch_request
    rv = self.dispatch_request()
.tox/c1/lib/python3.6/site-packages/flask/app.py:1824: in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
.tox/c1/lib/python3.6/site-packages/flask/views.py:88: in view
    return self.dispatch_request(*args, **kwargs)
.tox/c1/lib/python3.6/site-packages/invenio_rest/views.py:240: in dispatch_request
    *args, **kwargs
.tox/c1/lib/python3.6/site-packages/flask/views.py:158: in dispatch_request
    return meth(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <weko_search_ui.rest.IndexSearchResource object at 0x7fc076f46cf8>
kwargs = {}, FacetSearchSetting = <class 'weko_admin.models.FacetSearchSetting'>
get_facet_search_query = <MagicMock name='get_facet_search_query' id='140464607360056'>
page = 1, size = 20, is_search = 0, community_id = None, params = {}

    def get(self, **kwargs):
        """Search records.
    
        :returns: the search result containing hits and aggregations as
        returned by invenio-search.
        """
        from weko_admin.models import FacetSearchSetting
        from weko_admin.utils import get_facet_search_query
    
        page = request.values.get("page", 1, type=int)
        size = request.values.get("size", 20, type=int)
        is_search = request.values.get("is_search", 0 ,type=int ) #toppage and search_page is 1
        community_id = request.values.get("community")
        params = {}
        facets = get_facet_search_query()
        search_index = current_app.config["SEARCH_UI_SEARCH_INDEX"]
>       if facets and search_index and "post_filters" in facets[search_index]:
E       KeyError: 'test-weko'

weko_search_ui/rest.py:205: KeyError
_____________________________ test_delete_records ______________________________

i18n_app = <Flask 'testapp'>
db_activity = {'activity': <Activity 2>, 'item': {'id': '1', 'pid': {'type': 'depid', 'value': '1', 'revision_id': 0}, 'lang': 'ja',... 'http://purl.org/coar/resource_type/c_5794', 'resourcetype': 'conference paper'}]}, 'relation_version_is_last': True}}

    def test_delete_records(i18n_app, db_activity):
        with open("tests/data/search_result_2.json", "r") as json_file:
            search_result = json.load(json_file)
    
            with patch("weko_search_ui.utils.get_tree_items", return_value=[search_result]):
                with patch(
                    "invenio_records.api.Record.get_record",
                    return_value=db_activity["record"],
                ):
                    with patch(
                        "weko_deposit.api.WekoIndexer.update_es_data",
                        return_value=db_activity["record"],
                    ):
                        with patch(
                            "weko_deposit.api.WekoDeposit.delete_by_index_tree_id",
                            return_value="",
                        ):
                            with patch(
                                "invenio_records.api.Record.delete", return_value=""
                            ):
                                assert delete_records(33, ignore_items=[])
>                               assert delete_records(1, ignore_items=[])

tests/test_utils.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:249: in delete_records
    soft_delete(pid)
../weko-records-ui/weko_records_ui/utils.py:310: in soft_delete
    raise ex
../weko-records-ui/weko_records_ui/utils.py:291: in soft_delete
    dep.remove_feedback_mail()
../weko-deposit/weko_deposit/api.py:1653: in remove_feedback_mail
    self.indexer.update_feedback_mail_list(feedback_mail)
../weko-deposit/weko_deposit/api.py:391: in update_feedback_mail_list
    body=body
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/__init__.py:528: in update
    doc_type, id, '_update'), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 404
raw_data = '{"error":{"root_cause":[{"type":"document_missing_exception","reason":"[item-v1.0.0][b9e7f2dd-e77f-49f6-a27b-6ffc8870...-6ffc887048cc]: document missing","index_uuid":"Nd2dLndnT9KxV9hnvBL1KQ","shard":"1","index":"test-weko"},"status":404}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.NotFoundError: TransportError(404, 'document_missing_exception', '[item-v1.0.0][b9e7f2dd-e77f-49f6-a27b-6ffc887048cc]: document missing')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: NotFoundError
------------------------------ Captured log call -------------------------------
WARNING  elasticsearch:base.py:97 POST http://elasticsearch:9200/test-weko/item-v1.0.0/b9e7f2dd-e77f-49f6-a27b-6ffc887048cc/_update [status:404 request:0.133s]
_________________________ test_get_feedback_mail_list __________________________

i18n_app = <Flask 'testapp'>
db_records2 = [(<PersistentIdentifier depid:1 / rec:9f6f8092-125a-49c7-b2b3-fafd33e8d5f2 (R)>, <PersistentIdentifier recid:1 / rec:9...617258105262': {'resourceuri': 'http://purl.org/coar/resource_type/c_5794', 'resourcetype': 'conference paper'}}), ...]
es = <Elasticsearch([{'host': 'elasticsearch'}])>

    def test_get_feedback_mail_list(i18n_app, db_records2, es):
        search_instance = '{"size": 1, "query": {"bool": {"filter": [{"bool": {"must": [{"match": {"publish_status": "0"}}, {"range": {"publish_date": {"lte": "now/d"}}}, {"terms": {"path": ["1031", "1029", "1025", "952", "953", "943", "940", "1017", "1015", "1011", "881", "893", "872", "869", "758", "753", "742", "530", "533", "502", "494", "710", "702", "691", "315", "351", "288", "281", "759", "754", "744", "531", "534", "503", "495", "711", "704", "692", "316", "352", "289", "282", "773", "771", "767", "538", "539", "519", "510", "756", "745", "733", "337", "377", "308", "299", "2063", "2061", "2057", "1984", "1985", "1975", "1972", "2049", "2047", "2043", "1913", "1925", "1904", "1901", "1790", "1785", "1774", "1562", "1565", "1534", "1526", "1742", "1734", "1723", "1347", "1383", "1320", "1313", "1791", "1786", "1776", "1563", "1566", "1535", "1527", "1743", "1736", "1724", "1348", "1384", "1321", "1314", "1805", "1803", "1799", "1570", "1571", "1551", "1542", "1788", "1777", "1765", "1369", "1409", "1340", "1331", "4127", "4125", "4121", "4048", "4049", "4039", "4036", "4113", "4111", "4107", "3977", "3989", "3968", "3965", "3854", "3849", "3838", "3626", "3629", "3598", "3590", "3806", "3798", "3787", "3411", "3447", "3384", "3377", "3855", "3850", "3840", "3627", "3630", "3599", "3591", "3807", "3800", "3788", "3412", "3448", "3385", "3378", "3869", "3867", "3863", "3634", "3635", "3615", "3606", "3852", "3841", "3829", "3433", "3473", "3404", "3395", "1631495207665", "1631495247023", "1631495289664", "1631495340640", "1631510190230", "1631510251689", "1631510324260", "1631510380602", "1631510415574", "1631511387362", "1631511432362", "1631511521954", "1631511525655", "1631511606115", "1631511735866", "1631511740808", "1631511841882", "1631511874428", "1631511843164", "1631511845163", "1631512253601", "1633380618401", "1638171727119", "1638171753803", "1634120530242", "1636010714174", "1636010749240", "1638512895916", "1638512971664"]}}, {"bool": {"must": [{"match": {"publish_status": "0"}}, {"match": {"relation_version_is_last": "true"}}]}}, {"bool": {"should": [{"nested": {"query": {"multi_match": {"query": "simple", "operator": "and", "fields": ["content.attachment.content"]}}, "path": "content"}}, {"query_string": {"query": "simple", "default_operator": "and", "fields": ["search_*", "search_*.ja"]}}]}}]}}], "must": [{"match_all": {}}]}}, "aggs": {"Data Language": {"filter": {"bool": {"must": [{"term": {"publish_status": "0"}}]}}, "aggs": {"Data Language": {"terms": {"field": "language", "size": 1000}}}}, "Access": {"filter": {"bool": {"must": [{"term": {"publish_status": "0"}}]}}, "aggs": {"Access": {"terms": {"field": "accessRights", "size": 1000}}}}, "Location": {"filter": {"bool": {"must": [{"term": {"publish_status": "0"}}]}}, "aggs": {"Location": {"terms": {"field": "geoLocation.geoLocationPlace", "size": 1000}}}}, "Temporal": {"filter": {"bool": {"must": [{"term": {"publish_status": "0"}}]}}, "aggs": {"Temporal": {"terms": {"field": "temporal", "size": 1000}}}}, "Topic": {"filter": {"bool": {"must": [{"term": {"publish_status": "0"}}]}}, "aggs": {"Topic": {"terms": {"field": "subject.value", "size": 1000}}}}, "Distributor": {"filter": {"bool": {"must": [{"term": {"contributor.@attributes.contributorType": "Distributor"}}, {"term": {"publish_status": "0"}}]}}, "aggs": {"Distributor": {"terms": {"field": "contributor.contributorName", "size": 1000}}}}, "Data Type": {"filter": {"bool": {"must": [{"term": {"description.descriptionType": "Other"}}, {"term": {"publish_status": "0"}}]}}, "aggs": {"Data Type": {"terms": {"field": "description.value", "size": 1000}}}}}, "sort": [{"_id": {"order": "desc", "unmapped_type": "long"}}], "_source": {"excludes": ["content"]}}'
        execute_result = {
            "aggregations": {"doc_count": 1, "key": 2},
            "feedback_mail_list": {},
            "email_list": {},
            "buckets": [],
        }
        # mock_recordssearch = MagicMock(side_effect=MockRecordsSearch)
        # side_effect=mock_recordssearch
        with patch(
            "weko_search_ui.query.feedback_email_search_factory",
            return_value=search_instance,
        ):
>           assert get_feedback_mail_list() == {}

tests/test_utils.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:312: in get_feedback_mail_list
    search_instance.execute()
.tox/c1/lib/python3.6/site-packages/elasticsearch_dsl/search.py:706: in execute
    **self._params
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/__init__.py:636: in search
    doc_type, '_search'), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 400
raw_data = '{"error":{"root_cause":[{"type":"query_shard_exception","reason":"failed to create query: {\\n  \\"bool\\" : {\\n    ...l_state_exception","reason":"[nested] failed to find nested object under path [feedback_mail_list]"}}}]},"status":400}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.RequestError: TransportError(400, 'search_phase_execution_exception', 'failed to create query: {\n  "bool" : {\n    "must" : [\n      {\n        "nested" : {\n          "query" : {\n            "bool" : {\n              "must" : [\n                {\n                  "exists" : {\n                    "field" : "feedback_mail_list.email",\n                    "boost" : 1.0\n                  }\n                }\n              ],\n              "adjust_pure_negative" : true,\n              "boost" : 1.0\n            }\n          },\n          "path" : "feedback_mail_list",\n          "ignore_unmapped" : false,\n          "score_mode" : "avg",\n          "boost" : 1.0\n        }\n      },\n      {\n        "query_string" : {\n          "query" : "_type:record-v1.0.0 AND relation_version_is_last:true ",\n          "fields" : [ ],\n          "type" : "best_fields",\n          "default_operator" : "or",\n          "max_determinized_states" : 10000,\n          "enable_position_increments" : true,\n          "fuzziness" : "AUTO",\n          "fuzzy_prefix_length" : 0,\n          "fuzzy_max_expansions" : 50,\n          "phrase_slop" : 0,\n          "escape" : false,\n          "auto_generate_synonyms_phrase_query" : true,\n          "fuzzy_transpositions" : true,\n          "boost" : 1.0\n        }\n      }\n    ],\n    "adjust_pure_negative" : true,\n    "boost" : 1.0\n  }\n}')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: RequestError
------------------------------ Captured log setup ------------------------------
WARNING  elasticsearch:base.py:97 PUT http://elasticsearch:9200/test-weko-item-v1.0.0/_alias/test-weko [status:400 request:0.006s]
------------------------------ Captured log call -------------------------------
WARNING  elasticsearch:base.py:97 GET http://elasticsearch:9200/test-weko/_search?preference=4a4d20d732cd9f789541e54dd9eb6af8&version=false [status:400 request:0.012s]
__________________________ test_unpackage_import_file __________________________

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
mocker = <pytest_mock.plugin.MockerFixture object at 0x7fc07385ae48>
mocker_itemtype = None

    def test_unpackage_import_file(app, db,mocker, mocker_itemtype):
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)), "data", "item_map.json"
        )
        with open(filepath, encoding="utf-8") as f:
            item_map = json.load(f)
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)), "data", "item_type_mapping.json"
        )
        with open(filepath, encoding="utf-8") as f:
            item_type_mapping = json.load(f)
        mocker.patch("weko_records.serializers.utils.get_mapping", return_value=item_map)
        mocker.patch("weko_records.api.Mapping.get_record", return_value=item_type_mapping)
    
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)),
            "data",
            "unpackage_import_file/result.json",
        )
        with open(filepath, encoding="utf-8") as f:
            result = json.load(f)
    
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)),
            "data",
            "unpackage_import_file/result_force_new.json",
        )
        with open(filepath, encoding="utf-8") as f:
            result_force_new = json.load(f)
    
        path = os.path.join(
            os.path.dirname(os.path.realpath(__file__)), "data", "unpackage_import_file"
        )
        with app.test_request_context():
            with set_locale("en"):
>               assert unpackage_import_file(path, "items.csv", "csv", False) == result
E               AssertionError: assert [{'$schema': ...ac.jp'], ...}] == [{'$schema': ...ac.jp'], ...}]
E                 At index 0 diff: {'pos_index': ['Index A'], 'publish_status': 'public', 'feedback_mail': ['wekosoftware@nii.ac.jp'], 'edit_mode': 'Keep', 'metadata': {'pubdate': '2021-03-19', 'item_1617186331708': [{'subitem_1551255647225': 'ja_conference paperITEM00000001(public_open_access_open_access_simple)', 'subitem_1551255648112': 'ja'}, {'subitem_1551255647225': 'en_conference paperITEM00000001(public_open_access_simple)', 'subitem_1551255648112': 'en'}], 'item_1617186385884': [{'subitem_1551255720400': 'Alternative Title', 'subitem_1551255721061': 'en'}, {'subitem_155125572040...
E                 
E                 ...Full output truncated (569 lines hidden), use '-vv' to show

tests/test_utils.py:380: AssertionError
_____________________________ test_read_stats_file _____________________________

self = <sqlalchemy.engine.base.Connection object at 0x7fc072edd9b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0731c7e48>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2'>>
statement = 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, ...AS item_type_version_id, item_type.is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s'
parameters = {'id_1': 'test'}
args = (<sqlalchemy.dialects.postgresql.psycopg2.PGCompiler_psycopg2 object at 0x7fc07311e7f0>, [immutabledict({})])
conn = <sqlalchemy.pool._ConnectionFairy object at 0x7fc072edd0b8>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7fc07311e940>

    def _execute_context(
        self, dialect, constructor, statement, parameters, *args
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`.ResultProxy`."""
    
        try:
            try:
                conn = self.__connection
            except AttributeError:
                # escape "except AttributeError" before revalidating
                # to prevent misleading stacktraces in Py3K
                conn = None
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(dialect, self, conn, *args)
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )
    
        if context.compiled:
            context.pre_exec()
    
        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        if not context.executemany:
            parameters = parameters[0]
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self.engine.logger.info(statement)
            self.engine.logger.info(
                "%r", sql_util._repr_params(parameters, batches=10)
            )
    
        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
>                       cursor, statement, parameters, context
                    )

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0731c7e48>
cursor = <cursor object at 0x7fc0743a19f8; closed: -1>
statement = 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, ...AS item_type_version_id, item_type.is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s'
parameters = {'id_1': 'test'}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7fc07311e940>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.DataError: invalid input syntax for type integer: "test"
E       LINE 3: WHERE item_type.id = 'test'
E                                    ^

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:536: DataError

The above exception was the direct cause of the following exception:

i18n_app = <Flask 'testapp'>
db_itemtype = {'item_type': <ItemType 1>, 'item_type_mapping': <ItemTypeMapping 1>, 'item_type_name': <ItemTypeName 1>}
users = [{'email': 'noroleuser@test.org', 'id': 9, 'obj': <User 9>}, {'email': 'contributor@test.org', 'id': 2, 'obj': <User 2...ail': 'comadmin@test.org', 'id': 3, 'obj': <User 3>}, {'email': 'generaluser@test.org', 'id': 6, 'obj': <User 5>}, ...]

    def test_read_stats_file(i18n_app, db_itemtype, users):
        current_path = os.path.dirname(os.path.abspath(__file__))
        file_name_tsv = "sample_tsv.tsv"
        file_path_tsv = os.path.join(current_path, "data", "sample_file", file_name_tsv)
    
        file_name_csv = "sample_csv.csv"
        file_path_csv = os.path.join(current_path, "data", "sample_file", file_name_csv)
    
        file_name_tsv_2 = "sample_tsv_2.tsv"
        file_path_tsv_2 = os.path.join(current_path, "data", "sample_file", file_name_tsv_2)
    
        check_item_type = {
            "schema": "test",
            "is_lastest": "test",
            "name": "test",
            "item_type_id": "test",
        }
    
        with patch("flask_login.utils._get_user", return_value=users[3]["obj"]):
            with patch("weko_search_ui.utils.get_item_type", return_value=check_item_type):
>               assert read_stats_file(file_path_tsv, file_name_tsv, "tsv")

tests/test_utils.py:433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:859: in read_stats_file
    raise ex
weko_search_ui/utils.py:782: in read_stats_file
    check_item_type.get("item_type_id")
weko_search_ui/utils.py:3204: in handle_get_all_id_in_item_type
    item_type = ItemTypes.get_by_id(id_=item_type_id, with_deleted=True)
../weko-records/weko_records/api.py:640: in get_by_id
    return query.one_or_none()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3008: in one_or_none
    ret = list(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3081: in __iter__
    return self._execute_and_instances(context)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3106: in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:980: in execute
    return meth(self, multiparams, params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/sql/elements.py:273: in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1099: in _execute_clauseelement
    distilled_params,
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1240: in _execute_context
    e, statement, parameters, cursor, context
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1458: in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1236: in _execute_context
    cursor, statement, parameters, context
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc0731c7e48>
cursor = <cursor object at 0x7fc0743a19f8; closed: -1>
statement = 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, ...AS item_type_version_id, item_type.is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s'
parameters = {'id_1': 'test'}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7fc07311e940>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.DataError: (psycopg2.DataError) invalid input syntax for type integer: "test"
E       LINE 3: WHERE item_type.id = 'test'
E                                    ^
E        [SQL: 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, item_type.name_id AS item_type_name_id, item_type.harvesting_type AS item_type_harvesting_type, item_type.schema AS item_type_schema, item_type.form AS item_type_form, item_type.render AS item_type_render, item_type.tag AS item_type_tag, item_type.version_id AS item_type_version_id, item_type.is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s'] [parameters: {'id_1': 'test'}] (Background on this error at: http://sqlalche.me/e/9h9h)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:536: DataError
___________________ test_handle_check_and_prepare_index_tree ___________________

i18n_app = <Flask 'testapp'>
record_with_metadata = [{'$schema': 'https://localhost:8443/items/jsonschema/15', 'doi_ra': 'JaLC', 'edit_mode': 'Keep', 'errors': None, ...}...chema': 'https://localhost:8443/items/jsonschema/15', 'doi_ra': 'JaLC', 'edit_mode': 'Keep', 'errors': None, ...}, ...]
indices = {'index_dict': {'biblio_flag': False, 'browsing_group': '', 'browsing_role': 'Contributor', 'comment': '', ...}, 'index_non_dict': <Index 33>, 'index_non_dict_child': <Index 44>}

    def test_handle_check_and_prepare_index_tree(i18n_app, record_with_metadata, indices):
        list_record = [record_with_metadata[0]]
        can_edit_indexes = [indices["index_dict"]]
        item_2 = record_with_metadata[0]
    
        all_index_permission = False
>       assert not handle_check_and_prepare_index_tree(
            list_record, all_index_permission, can_edit_indexes
        )

tests/test_utils.py:812: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:1870: in handle_check_and_prepare_index_tree
    _index_ids = check(index_id, index_name_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

index_id = 1658883231990, index_name_path = 'IndexA'

    def check(index_id, index_name_path):
        """Check index_id/index_name.
    
        Args:
            index_id (str): Index id.
            index_name_path (str): Index name path.
    
        Returns:
            [bool]: Check result.
    
        """
        temp_res = []
        index_info = None
        try:
            index_info = Indexes.get_path_list([index_id])
        except Exception:
            db.session.rollback()
            current_app.logger.warning("Specified IndexID is invalid!")
    
        msg_not_exist = _("The specified {} does not exist in system.")
        if index_info and len(index_info) == 1:
            check_list = []
            check_list.append(index_info[0].name_en.replace(
                '-/-', current_app.config['WEKO_ITEMS_UI_INDEX_PATH_SPLIT']))
            if index_info[0].name:
                check_list.append(index_info[0].name.replace(
                    '-/-', current_app.config['WEKO_ITEMS_UI_INDEX_PATH_SPLIT']))
            if index_name_path and index_name_path not in check_list:
                warnings.append(
                    _("Specified {} does not match with existing index.").format(
                        "POS_INDEX"
                    )
                )
            temp_res = [index_info[0].cid]
        elif index_name_path:          # has pos_index info
            index_path_list = index_name_path.split(
>               current_app.config['WEKO_ITEMS_UI_INDEX_PATH_SPLIT'])
E           KeyError: 'WEKO_ITEMS_UI_INDEX_PATH_SPLIT'

weko_search_ui/utils.py:1805: KeyError
__________________ test_handle_check_and_prepare_index_tree2 ___________________

i18n_app = <Flask 'testapp'>
record_with_metadata = [{'$schema': 'https://localhost:8443/items/jsonschema/15', 'doi_ra': 'JaLC', 'edit_mode': 'Keep', 'errors': ['指定されたPOS...chema': 'https://localhost:8443/items/jsonschema/15', 'doi_ra': 'JaLC', 'edit_mode': 'Keep', 'errors': None, ...}, ...]
indices2 = None

    def test_handle_check_and_prepare_index_tree2(i18n_app, record_with_metadata, indices2):
        i18n_app.config["WEKO_ITEMS_UI_INDEX_PATH_SPLIT"] = "///"
        list_record = [record_with_metadata[0]]
    
        list_record[0]["metadata"]["path"] = []
        list_record[0]["pos_index"] = ["A///C"]
        all_index_permission = False
        handle_check_and_prepare_index_tree(
            list_record, all_index_permission, None
        )
        assert list_record[0]["metadata"]["path"] == []
    
        list_record[0]["metadata"]["path"] = []
        handle_check_and_prepare_index_tree(
            list_record, all_index_permission, [4]
        )
        assert list_record[0]["metadata"]["path"] == []
    
        list_record[0]["metadata"]["path"] = []
        handle_check_and_prepare_index_tree(
            list_record, all_index_permission, [2]
        )
>       assert list_record[0]["metadata"]["path"] == [2]
E       assert [] == [2]
E         Right contains one more item: 2
E         Full diff:
E         - [2]
E         ?  -
E         + []

tests/test_utils.py:860: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  flask.app:utils.py:1786 Specified IndexID is invalid!
WARNING  flask.app:utils.py:1786 Specified IndexID is invalid!
WARNING  flask.app:utils.py:1786 Specified IndexID is invalid!
_________________ test_handle_check_and_prepare_feedback_mail __________________

i18n_app = <Flask 'testapp'>
record_with_metadata = [{'$schema': 'https://localhost:8443/items/jsonschema/15', 'doi_ra': 'JaLC', 'edit_mode': 'Keep', 'errors': None, ...}...chema': 'https://localhost:8443/items/jsonschema/15', 'doi_ra': 'JaLC', 'edit_mode': 'Keep', 'errors': None, ...}, ...]

    def test_handle_check_and_prepare_feedback_mail(i18n_app, record_with_metadata):
        list_record = [record_with_metadata[0]]
    
        # Doesn't return any value
>       assert not handle_check_and_prepare_feedback_mail(list_record)

tests/test_utils.py:868: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:1907: in handle_check_and_prepare_feedback_mail
    email_checked = check_email_existed(mail)
../weko-authors/weko_authors/utils.py:90: in check_email_existed
    body=body
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/__init__.py:636: in search
    doc_type, '_search'), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:314: in perform_request
    status, headers_response, data = connection.perform_request(method, url, params, body, headers=headers, ignore=ignore, timeout=timeout)
.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/http_requests.py:90: in perform_request
    self._raise_error(response.status_code, raw_data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <RequestsHttpConnection: http://elasticsearch:9200>, status_code = 404
raw_data = '{"error":{"root_cause":[{"type":"index_not_found_exception","reason":"no such index","resource.type":"index_or_alias"...index","resource.type":"index_or_alias","resource.id":"-authors","index_uuid":"_na_","index":"-authors"},"status":404}'

    def _raise_error(self, status_code, raw_data):
        """ Locate appropriate exception and raise it. """
        error_message = raw_data
        additional_info = None
        try:
            if raw_data:
                additional_info = json.loads(raw_data)
                error_message = additional_info.get('error', error_message)
                if isinstance(error_message, dict) and 'type' in error_message:
                    error_message = error_message['type']
        except (ValueError, TypeError) as err:
            logger.warning('Undecodable raw error response from server: %s', err)
    
>       raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
E       elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')

.tox/c1/lib/python3.6/site-packages/elasticsearch/connection/base.py:125: NotFoundError
------------------------------ Captured log call -------------------------------
WARNING  elasticsearch:base.py:97 GET http://elasticsearch:9200/-authors/author-v1.0.0/_search [status:404 request:0.005s]
____________________________ test_handle_check_cnri ____________________________

i18n_app = <Flask 'testapp'>

    def test_handle_check_cnri(i18n_app):
        item = MagicMock()
        # item = {
        #     "id": 1,
        #     "cnri": None,
        #     "is_change_identifier": True
        # }
        # Doesn't return any value
>       assert not handle_check_cnri([item])

tests/test_utils.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:1965: in handle_check_cnri
    if prefix != Handle().get_prefix():
../weko-handle/weko_handle/api.py:97: in get_prefix
    return PIDClientCredentials.load_from_JSON(self.credential_path).get_prefix()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

json_filename = None

    @staticmethod
    def load_from_JSON(json_filename):
        '''
        Create a new instance of a PIDClientCredentials with information read
        from a local JSON file.
    
        :param json_filename: The path to the json credentials file. The json
            file should have the following format:
    
                .. code:: json
    
                    {
                        "handle_server_url": "https://url.to.your.handle.server",
                        "username": "index:prefix/suffix",
                        "password": "ZZZZZZZ",
                        "prefix": "prefix_to_use_for_writing_handles",
                        "handleowner": "username_to_own_handles"
                    }
    
            Any additional key-value-pairs are stored in the instance as
            config.
        :raises: :exc:`~b2handle.handleexceptions.CredentialsFormatError`
        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`
        :return: An instance.
        '''
        try:
>           jsonfilecontent = json.loads(open(json_filename, 'r').read())
E           TypeError: expected str, bytes or os.PathLike object, not NoneType

.tox/c1/lib/python3.6/site-packages/b2handle/clientcredentials.py:54: TypeError
____________________________ test_handle_check_doi _____________________________

value = <MagicMock name='mock.pid_recid.object_uuid' id='140464448319104'>

    @staticmethod
    def _coerce(value):
        if value and not isinstance(value, uuid.UUID):
            try:
>               value = uuid.UUID(value)

.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/types/uuid.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'",) raised in repr()] UUID object at 0x7fc06d8d0a90>
hex = <MagicMock name='mock.pid_recid.object_uuid.replace().replace().strip().replace()' id='140464448588152'>
bytes = None, bytes_le = None, fields = None, int = None, version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
>               raise ValueError('badly formed hexadecimal UUID string')
E               ValueError: badly formed hexadecimal UUID string

/usr/local/lib/python3.6/uuid.py:140: ValueError

During handling of the above exception, another exception occurred:

self = <sqlalchemy.engine.base.Connection object at 0x7fc06d8d0908>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc06d8c65f8>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2'>>
statement = <sqlalchemy.dialects.postgresql.psycopg2.PGCompiler_psycopg2 object at 0x7fc06d8d0898>
parameters = [immutabledict({})]
args = (<sqlalchemy.dialects.postgresql.psycopg2.PGCompiler_psycopg2 object at 0x7fc06d8d0898>, [immutabledict({})])
conn = <sqlalchemy.pool._ConnectionFairy object at 0x7fc06d8d00b8>

    def _execute_context(
        self, dialect, constructor, statement, parameters, *args
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`.ResultProxy`."""
    
        try:
            try:
                conn = self.__connection
            except AttributeError:
                # escape "except AttributeError" before revalidating
                # to prevent misleading stacktraces in Py3K
                conn = None
            if conn is None:
                conn = self._revalidate_connection()
    
>           context = constructor(dialect, self, conn, *args)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2'>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc06d8c65f8>
connection = <sqlalchemy.engine.base.Connection object at 0x7fc06d8d0908>
dbapi_connection = <sqlalchemy.pool._ConnectionFairy object at 0x7fc06d8d00b8>
compiled = <sqlalchemy.dialects.postgresql.psycopg2.PGCompiler_psycopg2 object at 0x7fc06d8d0898>
parameters = []

    @classmethod
    def _init_compiled(
        cls, dialect, connection, dbapi_connection, compiled, parameters
    ):
        """Initialize execution context for a Compiled construct."""
    
        self = cls.__new__(cls)
        self.root_connection = connection
        self._dbapi_connection = dbapi_connection
        self.dialect = connection.dialect
    
        self.compiled = compiled
    
        # this should be caught in the engine before
        # we get here
        assert compiled.can_execute
    
        self.execution_options = compiled.execution_options.union(
            connection._execution_options
        )
    
        self.result_column_struct = (
            compiled._result_columns,
            compiled._ordered_columns,
            compiled._textual_ordered_columns,
        )
    
        self.unicode_statement = util.text_type(compiled)
        if not dialect.supports_unicode_statements:
            self.statement = self.unicode_statement.encode(
                self.dialect.encoding
            )
        else:
            self.statement = self.unicode_statement
    
        self.isinsert = compiled.isinsert
        self.isupdate = compiled.isupdate
        self.isdelete = compiled.isdelete
        self.is_text = compiled.isplaintext
    
        if not parameters:
            self.compiled_parameters = [compiled.construct_params()]
        else:
            self.compiled_parameters = [
                compiled.construct_params(m, _group_number=grp)
                for grp, m in enumerate(parameters)
            ]
    
            self.executemany = len(parameters) > 1
    
        self.cursor = self.create_cursor()
    
        if self.isinsert or self.isupdate or self.isdelete:
            self.is_crud = True
            self._is_explicit_returning = bool(compiled.statement._returning)
            self._is_implicit_returning = bool(
                compiled.returning and not compiled.statement._returning
            )
    
        if self.compiled.insert_prefetch or self.compiled.update_prefetch:
            if self.executemany:
                self._process_executemany_defaults()
            else:
                self._process_executesingle_defaults()
    
        processors = compiled._bind_processors
    
        if compiled.contains_expanding_parameters:
            positiontup = self._expand_in_parameters(compiled, processors)
        elif compiled.positional:
            positiontup = self.compiled.positiontup
    
        # Convert the dictionary of bind parameter values
        # into a dict or list to be sent to the DBAPI's
        # execute() or executemany() method.
        parameters = []
        if compiled.positional:
            for compiled_params in self.compiled_parameters:
                param = []
                for key in positiontup:
                    if key in processors:
                        param.append(processors[key](compiled_params[key]))
                    else:
                        param.append(compiled_params[key])
                parameters.append(dialect.execute_sequence_format(param))
        else:
            encode = not dialect.supports_unicode_statements
            for compiled_params in self.compiled_parameters:
    
                if encode:
                    param = dict(
                        (
                            dialect._encoder(key)[0],
                            processors[key](compiled_params[key])
                            if key in processors
                            else compiled_params[key],
                        )
                        for key in compiled_params
                    )
                else:
                    param = dict(
                        (
                            key,
                            processors[key](compiled_params[key])
                            if key in processors
                            else compiled_params[key],
                        )
>                       for key in compiled_params
                    )

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <dict_keyiterator object at 0x7fc06d8d5098>

        (
            key,
            processors[key](compiled_params[key])
            if key in processors
            else compiled_params[key],
        )
>       for key in compiled_params
    )

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = <MagicMock name='mock.pid_recid.object_uuid' id='140464448319104'>

    def process(value):
>       return impl_processor(process_param(value, dialect))

.tox/c1/lib/python3.6/site-packages/sqlalchemy/sql/type_api.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = UUIDType()
value = <MagicMock name='mock.pid_recid.object_uuid' id='140464448319104'>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc06d8c65f8>

    def process_bind_param(self, value, dialect):
        if value is None:
            return value
    
        if not isinstance(value, uuid.UUID):
>           value = self._coerce(value)

.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/types/uuid.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = <MagicMock name='mock.pid_recid.object_uuid' id='140464448319104'>

    @staticmethod
    def _coerce(value):
        if value and not isinstance(value, uuid.UUID):
            try:
                value = uuid.UUID(value)
    
            except (TypeError, ValueError):
>               value = uuid.UUID(bytes=value)

.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/types/uuid.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'",) raised in repr()] UUID object at 0x7fc06d8fc780>
hex = None
bytes = <MagicMock name='mock.pid_recid.object_uuid' id='140464448319104'>
bytes_le = None, fields = None, int = None, version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
                raise ValueError('badly formed hexadecimal UUID string')
            int = int_(hex, 16)
        if bytes_le is not None:
            if len(bytes_le) != 16:
                raise ValueError('bytes_le is not a 16-char string')
            bytes = (bytes_le[4-1::-1] + bytes_le[6-1:4-1:-1] +
                     bytes_le[8-1:6-1:-1] + bytes_le[8:])
        if bytes is not None:
            if len(bytes) != 16:
>               raise ValueError('bytes is not a 16-char string')
E               ValueError: bytes is not a 16-char string

/usr/local/lib/python3.6/uuid.py:149: ValueError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>

    def test_handle_check_doi(app):
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)),
            "data",
            "list_records",
            "list_records.json",
        )
        with open(filepath, encoding="utf-8") as f:
            list_record = json.load(f)
        assert handle_check_doi(list_record) == None
    
        # case new items with doi_ra
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)),
            "data",
            "list_records",
            "b4_handle_check_doi.json",
        )
        with open(filepath, encoding="utf-8") as f:
            list_record = json.load(f)
        assert handle_check_doi(list_record) == None
    
        # item = {
        #     "doi_ra": "JaLC",
        #     "is_change_identifier": True,
        #     "status": "new"
        # }
        item = MagicMock()
        with patch("weko_deposit.api.WekoRecord.get_record_by_pid", return_value="1"):
            assert not handle_check_doi([item])
    
        item2 = {"doi_ra": "JaLC", "is_change_identifier": False, "status": "keep"}
        mock = MagicMock()
        mock2 = MagicMock()
        mock3 = MagicMock()
        mock2.object_uuid = mock3
        mock.pid_recid = mock2
    
        # def myfunc():
        #     return 1,2
        # mock.get_idt_registration_data = myfunc
    
        with patch("weko_deposit.api.WekoRecord.get_record_by_pid", return_value=mock):
            # with patch("weko_workflow.utils.IdentifierHandle", return_value=mock):
>           assert not handle_check_doi([item2])

tests/test_utils.py:982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:2166: in handle_check_doi
    identifier = IdentifierHandle(pid.object_uuid)
../weko-workflow/weko_workflow/utils.py:1159: in __init__
    self.metadata_mapping = MappingData(item_id)
../weko-workflow/weko_workflow/utils.py:1034: in __init__
    self.record = WekoRecord.get_record(item_id) if item_id else record
../invenio-records/invenio_records/api.py:206: in get_record
    obj = query.one()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3039: in one
    ret = self.one_or_none()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3008: in one_or_none
    ret = list(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3081: in __iter__
    return self._execute_and_instances(context)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3106: in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:980: in execute
    return meth(self, multiparams, params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/sql/elements.py:273: in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1099: in _execute_clauseelement
    distilled_params,
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1174: in _execute_context
    e, util.text_type(statement), parameters, None, None
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1458: in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1171: in _execute_context
    context = constructor(dialect, self, conn, *args)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:729: in _init_compiled
    for key in compiled_params
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:729: in <genexpr>
    for key in compiled_params
.tox/c1/lib/python3.6/site-packages/sqlalchemy/sql/type_api.py:1189: in process
    return impl_processor(process_param(value, dialect))
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/types/uuid.py:68: in process_bind_param
    value = self._coerce(value)
.tox/c1/lib/python3.6/site-packages/sqlalchemy_utils/types/uuid.py:59: in _coerce
    value = uuid.UUID(bytes=value)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'",) raised in repr()] UUID object at 0x7fc06d8fc780>
hex = None
bytes = <MagicMock name='mock.pid_recid.object_uuid' id='140464448319104'>
bytes_le = None, fields = None, int = None, version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
                raise ValueError('badly formed hexadecimal UUID string')
            int = int_(hex, 16)
        if bytes_le is not None:
            if len(bytes_le) != 16:
                raise ValueError('bytes_le is not a 16-char string')
            bytes = (bytes_le[4-1::-1] + bytes_le[6-1:4-1:-1] +
                     bytes_le[8-1:6-1:-1] + bytes_le[8:])
        if bytes is not None:
            if len(bytes) != 16:
>               raise ValueError('bytes is not a 16-char string')
E               sqlalchemy.exc.StatementError: (builtins.ValueError) bytes is not a 16-char string [SQL: 'SELECT records_metadata.created AS records_metadata_created, records_metadata.updated AS records_metadata_updated, records_metadata.id AS records_metadata_id, records_metadata.json AS records_metadata_json, records_metadata.version_id AS records_metadata_version_id \nFROM records_metadata \nWHERE records_metadata.id = %(id_1)s AND records_metadata.json IS NOT NULL'] [parameters: [{}]]

/usr/local/lib/python3.6/uuid.py:149: StatementError
_________________________ test_handle_fill_system_item _________________________

self = <sqlalchemy.engine.base.Connection object at 0x7fc0689e3ac8>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc068e7f860>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2'>>
statement = 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, ....is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s AND item_type.is_deleted IS false'
parameters = {'id_1': 15}
args = (<sqlalchemy.dialects.postgresql.psycopg2.PGCompiler_psycopg2 object at 0x7fc0689e3a58>, [immutabledict({})])
conn = <sqlalchemy.pool._ConnectionFairy object at 0x7fc0689e3278>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7fc0689e3ba8>

    def _execute_context(
        self, dialect, constructor, statement, parameters, *args
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`.ResultProxy`."""
    
        try:
            try:
                conn = self.__connection
            except AttributeError:
                # escape "except AttributeError" before revalidating
                # to prevent misleading stacktraces in Py3K
                conn = None
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(dialect, self, conn, *args)
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )
    
        if context.compiled:
            context.pre_exec()
    
        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        if not context.executemany:
            parameters = parameters[0]
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self.engine.logger.info(statement)
            self.engine.logger.info(
                "%r", sql_util._repr_params(parameters, batches=10)
            )
    
        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
>                       cursor, statement, parameters, context
                    )

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc068e7f860>
cursor = <cursor object at 0x7fc0699d6520; closed: -1>
statement = 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, ....is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s AND item_type.is_deleted IS false'
parameters = {'id_1': 15}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7fc0689e3ba8>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.ProgrammingError: relation "item_type" does not exist
E       LINE 2: FROM item_type 
E                    ^

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:536: ProgrammingError

The above exception was the direct cause of the following exception:

app = <Flask 'testapp'>
test_list_records = [{'input': [{'$schema': 'https://localhost:8443/items/jsonschema/15', 'edit_mode': 'Keep', 'errors': None, 'feedback_m...e': 'Keep', 'errors': ['Please specify PubDate with YYYY-MM-DD.'], 'feedback_mail': ['wekosoftware@nii.ac.jp'], ...}]}]
mocker = <pytest_mock.plugin.MockerFixture object at 0x7fc068ea9f98>

    def test_handle_fill_system_item(app, test_list_records, mocker):
    
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)), "data", "item_map.json"
        )
        with open(filepath, encoding="utf-8") as f:
            item_map = json.load(f)
    
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)), "data", "item_type_mapping.json"
        )
        with open(filepath, encoding="utf-8") as f:
            item_type_mapping = json.load(f)
        mocker.patch("weko_records.serializers.utils.get_mapping", return_value=item_map)
        mocker.patch("weko_records.api.Mapping.get_record", return_value=item_type_mapping)
    
        filepath = os.path.join(
            os.path.dirname(os.path.realpath(__file__)),
            "data",
            "list_records/list_records_fill_system.json",
        )
        with open(filepath, encoding="utf-8") as f:
            list_record = json.load(f)
    
        items = []
        items_result = []
    
        for a in VERSION_TYPE_URI:
            item = copy.deepcopy(list_record[0])
            item["metadata"]["item_1617265215918"]["subitem_1522305645492"] = a
            item["metadata"]["item_1617265215918"][
                "subitem_1600292170262"
            ] = VERSION_TYPE_URI[a]
            item["metadata"]["item_1617186476635"]["subitem_1522299639480"] = "open access"
            item["metadata"]["item_1617186476635"][
                "subitem_1600958577026"
            ] = ACCESS_RIGHT_TYPE_URI["open access"]
            item["metadata"]["item_1617258105262"]["resourcetype"] = "conference paper"
            item["metadata"]["item_1617258105262"]["resourceuri"] = RESOURCE_TYPE_URI[
                "conference paper"
            ]
            item["warnings"] = []
            item["errors"] = []
            items_result.append(item)
            item2 = copy.deepcopy(item)
            item2["metadata"]["item_1617265215918"]["subitem_1522305645492"] = a
            item2["metadata"]["item_1617265215918"]["subitem_1600292170262"] = ""
            items.append(item2)
    
        for a in ACCESS_RIGHT_TYPE_URI:
            item = copy.deepcopy(list_record[0])
            item["metadata"]["item_1617265215918"]["subitem_1522305645492"] = "VoR"
            item["metadata"]["item_1617265215918"][
                "subitem_1600292170262"
            ] = VERSION_TYPE_URI["VoR"]
            item["metadata"]["item_1617186476635"]["subitem_1522299639480"] = a
            item["metadata"]["item_1617186476635"][
                "subitem_1600958577026"
            ] = ACCESS_RIGHT_TYPE_URI[a]
            item["metadata"]["item_1617258105262"]["resourcetype"] = "conference paper"
            item["metadata"]["item_1617258105262"]["resourceuri"] = RESOURCE_TYPE_URI[
                "conference paper"
            ]
            item["warnings"] = []
            item["errors"] = []
            items_result.append(item)
            item2 = copy.deepcopy(item)
            item2["metadata"]["item_1617186476635"]["subitem_1522299639480"] = a
            item2["metadata"]["item_1617186476635"]["subitem_1600958577026"] = ""
            items.append(item2)
    
        for a in RESOURCE_TYPE_URI:
            item = copy.deepcopy(list_record[0])
            item["metadata"]["item_1617265215918"]["subitem_1522305645492"] = "VoR"
            item["metadata"]["item_1617265215918"][
                "subitem_1600292170262"
            ] = VERSION_TYPE_URI["VoR"]
            item["metadata"]["item_1617186476635"]["subitem_1522299639480"] = "open access"
            item["metadata"]["item_1617186476635"][
                "subitem_1600958577026"
            ] = ACCESS_RIGHT_TYPE_URI["open access"]
            item["metadata"]["item_1617258105262"]["resourcetype"] = a
            item["metadata"]["item_1617258105262"]["resourceuri"] = RESOURCE_TYPE_URI[a]
            item["warnings"] = []
            item["errors"] = []
            items_result.append(item)
            item2 = copy.deepcopy(item)
            item2["metadata"]["item_1617258105262"]["resourcetype"] = a
            item2["metadata"]["item_1617258105262"]["resourceuri"] = ""
            items.append(item2)
    
        # with open("items.json","w") as f:
        #     json.dump(items,f)
    
        # with open("items_result.json","w") as f:
        #     json.dump(items_result,f)
    
        # filepath = os.path.join(os.path.dirname(os.path.realpath(__file__)),"data/handle_fill_system_item/items.json")
        # with open(filepath,encoding="utf-8") as f:
        #     items = json.load(f)
    
        # filepath = os.path.join(os.path.dirname(os.path.realpath(__file__)),"data/handle_fill_system_item/items_result.json")
        # with open(filepath,encoding="utf-8") as f:
        #     items_result = json.load(f)
    
        with app.test_request_context():
            with set_locale("en"):
>               handle_fill_system_item(items)

tests/test_utils.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
weko_search_ui/utils.py:2882: in handle_fill_system_item
    item_map = get_mapping(item_type_id, "jpcoar_mapping")
../weko-records/weko_records/serializers/utils.py:62: in get_mapping
    item_type_list = ItemTypes.get_by_id(item_type_id).render.get('table_row')
../weko-records/weko_records/api.py:640: in get_by_id
    return query.one_or_none()
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3008: in one_or_none
    ret = list(self)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3081: in __iter__
    return self._execute_and_instances(context)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/query.py:3106: in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:980: in execute
    return meth(self, multiparams, params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/sql/elements.py:273: in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1099: in _execute_clauseelement
    distilled_params,
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1240: in _execute_context
    e, statement, parameters, cursor, context
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1458: in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:296: in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/util/compat.py:276: in reraise
    raise value.with_traceback(tb)
.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/base.py:1236: in _execute_context
    cursor, statement, parameters, context
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7fc068e7f860>
cursor = <cursor object at 0x7fc0699d6520; closed: -1>
statement = 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, ....is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s AND item_type.is_deleted IS false'
parameters = {'id_1': 15}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7fc0689e3ba8>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) relation "item_type" does not exist
E       LINE 2: FROM item_type 
E                    ^
E        [SQL: 'SELECT item_type.created AS item_type_created, item_type.updated AS item_type_updated, item_type.id AS item_type_id, item_type.name_id AS item_type_name_id, item_type.harvesting_type AS item_type_harvesting_type, item_type.schema AS item_type_schema, item_type.form AS item_type_form, item_type.render AS item_type_render, item_type.tag AS item_type_tag, item_type.version_id AS item_type_version_id, item_type.is_deleted AS item_type_is_deleted \nFROM item_type \nWHERE item_type.id = %(id_1)s AND item_type.is_deleted IS false'] [parameters: {'id_1': 15}] (Background on this error at: http://sqlalche.me/e/f405)

.tox/c1/lib/python3.6/site-packages/sqlalchemy/engine/default.py:536: ProgrammingError
=============================== warnings summary ===============================
.tox/c1/lib/python3.6/site-packages/blinker/base.py:110
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/blinker/base.py:110: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/blinker/base.py:180
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/blinker/base.py:180: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/blinker/base.py:252
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/blinker/base.py:252: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/babel/core.py:1130
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/babel/core.py:1130: DeprecationWarning: invalid escape sequence \s
    """

.tox/c1/lib/python3.6/site-packages/babel/dates.py:1158
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/babel/dates.py:1158: DeprecationWarning: invalid escape sequence \d
    numbers = re.findall('(\d+)', string)

.tox/c1/lib/python3.6/site-packages/babel/dates.py:1201
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/babel/dates.py:1201: DeprecationWarning: invalid escape sequence \d
    numbers = re.findall('(\d+)', string)

.tox/c1/lib/python3.6/site-packages/babel/localtime/_unix.py:103
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/babel/localtime/_unix.py:103: DeprecationWarning: invalid escape sequence \s
    zone_re = re.compile('\s*ZONE\s*=\s*\"')

.tox/c1/lib/python3.6/site-packages/babel/localtime/_unix.py:104
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/babel/localtime/_unix.py:104: DeprecationWarning: invalid escape sequence \s
    timezone_re = re.compile('\s*TIMEZONE\s*=\s*\"')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:24
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:24: DeprecationWarning: invalid escape sequence \[
    _ESCAPE_RE = re.compile('\[[^\[\]]*\]')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:26
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:26: DeprecationWarning: invalid escape sequence \d
    _ONE_OR_MORE_DIGIT_RE = re.compile('\d+')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:27
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:27: DeprecationWarning: invalid escape sequence \d
    _ONE_OR_TWO_DIGIT_RE = re.compile('\d{1,2}')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:28
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:28: DeprecationWarning: invalid escape sequence \d
    _FOUR_DIGIT_RE = re.compile('\d{4}')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:29
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:29: DeprecationWarning: invalid escape sequence \d
    _TWO_DIGIT_RE = re.compile('\d{2}')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:30
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:30: DeprecationWarning: invalid escape sequence \-
    _TZ_RE = re.compile('[+\-]?\d{2}:?(\d{2})?')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:31
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:31: DeprecationWarning: invalid escape sequence \w
    _TZ_NAME_RE = re.compile('\w[\w+\-/]+')

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:49
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:49: DeprecationWarning: invalid escape sequence \d
    'X': re.compile('\d+'),

.tox/c1/lib/python3.6/site-packages/arrow/parser.py:310
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/arrow/parser.py:310: DeprecationWarning: invalid escape sequence \-
    _TZINFO_RE = re.compile('([+\-])?(\d\d):?(\d\d)?')

.tox/c1/lib/python3.6/site-packages/passlib/context.py:231
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/passlib/context.py:231: DeprecationWarning: invalid escape sequence \;
    elif any(c in source for c in "\n\r\t") or not source.strip(" \t./\;:"):

.tox/c1/lib/python3.6/site-packages/passlib/context.py:2240
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/passlib/context.py:2240: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/passlib/context.py:2323
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/passlib/context.py:2323: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/passlib/context.py:2406
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/passlib/context.py:2406: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:223
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:223: DeprecationWarning: invalid escape sequence \s
    ('\s+', Text),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:316
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:316: DeprecationWarning: invalid escape sequence \]
    (r'(/)(\[' + _dot + '*?\])(' + _dot + r'*\n)',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:333
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:333: DeprecationWarning: invalid escape sequence \}
    (r'\{(,\n|' + _dot + ')*?\}', using(RubyLexer)),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:334
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:334: DeprecationWarning: invalid escape sequence \]
    (r'\[' + _dot + '*?\]', using(RubyLexer)),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:343
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:343: DeprecationWarning: invalid escape sequence \}
    (r'(#\{)(' + _dot + '*?)(\})',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:376
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:376: DeprecationWarning: invalid escape sequence \}
    (r'(#\{)(' + _dot + '*?)(\})',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:425
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:425: DeprecationWarning: invalid escape sequence \]
    (r'(/)(\[' + _dot + '*?\])(' + _dot + r'*\n)',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:445
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:445: DeprecationWarning: invalid escape sequence \}
    (r'\{(,\n|' + _dot + ')*?\}', using(ScalaLexer)),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:446
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:446: DeprecationWarning: invalid escape sequence \]
    (r'\[' + _dot + '*?\]', using(ScalaLexer)),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:455
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:455: DeprecationWarning: invalid escape sequence \}
    (r'(#\{)(' + _dot + '*?)(\})',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:488
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:488: DeprecationWarning: invalid escape sequence \}
    (r'(#\{)(' + _dot + '*?)(\})',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:533
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:533: DeprecationWarning: invalid escape sequence \]
    (r'(/)(\[' + _dot + '*?\])(' + _dot + r'*\n)',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:554
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:554: DeprecationWarning: invalid escape sequence \}
    (r'\{(,\n|' + _dot + ')*?\}', using(ScalaLexer)),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:555
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:555: DeprecationWarning: invalid escape sequence \]
    (r'\[' + _dot + '*?\]', using(ScalaLexer)),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:564
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:564: DeprecationWarning: invalid escape sequence \}
    (r'(#\{)(' + _dot + '*?)(\})',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:597
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/html.py:597: DeprecationWarning: invalid escape sequence \}
    (r'(#\{)(' + _dot + '*?)(\})',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/javascript.py:538
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/javascript.py:538: DeprecationWarning: invalid escape sequence \s
    if re.search('^(import.+(from\s+)?["\']|'

.tox/c1/lib/python3.6/site-packages/pygments/lexers/javascript.py:539
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/javascript.py:539: DeprecationWarning: invalid escape sequence \s
    '(export\s*)?(interface|class|function)\s+)',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/javascript.py:1018
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/javascript.py:1018: DeprecationWarning: invalid escape sequence \s
    if re.search('^\s*@import\s+[<"]', text, re.MULTILINE):

.tox/c1/lib/python3.6/site-packages/pygments/lexers/jvm.py:260
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/jvm.py:260: DeprecationWarning: invalid escape sequence \d
    letter_letter_digit = u'%s(?:%s|\d)*' % (letter, letter)

.tox/c1/lib/python3.6/site-packages/pygments/lexers/jvm.py:692
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/jvm.py:692: DeprecationWarning: invalid escape sequence \w
    u'(?![\w!:?])', Name.Function),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/jvm.py:1261
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/jvm.py:1261: DeprecationWarning: invalid escape sequence \w
    ('`?[a-zA-Z_][\w$]*', Name),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:406
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:406: DeprecationWarning: invalid escape sequence \(
    _prompt_re = re.compile('irb\([a-zA-Z_]\w*\):\d{3}:\d+[>*"\'] '

.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:407
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:407: DeprecationWarning: invalid escape sequence \?
    '|>> |\?> ')

.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:501
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:501: DeprecationWarning: invalid escape sequence \w
    ('[A-Z]\w*', Name.Constant),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:502
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:502: DeprecationWarning: invalid escape sequence \w
    ('@[a-zA-Z_]\w*', Name.Variable.Instance),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:503
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:503: DeprecationWarning: invalid escape sequence \w
    ('@@[a-zA-Z_]\w*', Name.Variable.Class),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:505
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/ruby.py:505: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/actionscript.py:128
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/actionscript.py:128: DeprecationWarning: invalid escape sequence \.
    typeidentifier = identifier + '(?:\.<\w+>)?'

.tox/c1/lib/python3.6/site-packages/pygments/lexers/actionscript.py:235
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/actionscript.py:235: DeprecationWarning: invalid escape sequence \s
    ('\s+', Text),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/php.py:176
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/php.py:176: DeprecationWarning: invalid escape sequence \}
    (r'\$\{\$+' + _ident_inner + '\}', Name.Variable),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/php.py:217
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/php.py:217: DeprecationWarning: invalid escape sequence \[
    (r'\$' + _ident_inner + '(\[\S+?\]|->' + _ident_inner + ')?',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:441
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:441: DeprecationWarning: invalid escape sequence \(
    (r'(' + qname + ')(\()?', bygroups(Name, Punctuation), 'operator'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:646
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:646: DeprecationWarning: invalid escape sequence \*
    (ncname + ':\*', Name, 'operator'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:647
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:647: DeprecationWarning: invalid escape sequence \*
    ('\*:'+ncname, Name.Tag, 'operator'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:648
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:648: DeprecationWarning: invalid escape sequence \*
    ('\*', Name.Tag, 'operator'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:875
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/webmisc.py:875: DeprecationWarning: invalid escape sequence \`
    """

.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:142
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:142: DeprecationWarning: invalid escape sequence \(
    ("(?<=\()(%s)" % '|'.join(re.escape(entry) + ' ' for entry in builtins),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:324
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:324: DeprecationWarning: invalid escape sequence \s
    (r'#+nil' + terminated + '\s*\(', Comment.Preproc, 'commented-form'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:336
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:336: DeprecationWarning: invalid escape sequence \*
    (r'\*' + symbol + '\*', Name.Variable.Global),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:2157
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/lisp.py:2157: DeprecationWarning: invalid escape sequence \*
    (r'\*' + symbol + '\*', Name.Variable.Global),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:183
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:183: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:187
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:187: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name.Function, '#pop'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:191
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:191: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name.Class, '#pop')

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:268
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:268: DeprecationWarning: invalid escape sequence \w
    '((\w+)((\.\w+)|(\[[^\]]+\]))*)?'  # field name

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:269
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:269: DeprecationWarning: invalid escape sequence \!
    '(\![sra])?'                       # conversion

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:270
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:270: DeprecationWarning: invalid escape sequence \:
    '(\:(.?[<>=\^])?[-+ ]?#?0?(\d+)?,?(\.\d+)?[E-GXb-gnosx%]?)?'

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:271
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:271: DeprecationWarning: invalid escape sequence \}
    '\}', String.Interpol),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:674
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:674: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:677
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:677: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name.Function, '#pop')

.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:694
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/python.py:694: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name.Class, '#pop')

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:211
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:211: DeprecationWarning: invalid escape sequence \s
    if re.search('(?:my|our)\s+[$@%(]', text):

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:229
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:229: DeprecationWarning: invalid escape sequence \w
    PERL6_IDENTIFIER_RANGE = "['\w:-]"

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:498
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:498: DeprecationWarning: invalid escape sequence \s
    (r'(regex|token|rule)(?!' + PERL6_IDENTIFIER_RANGE + ')(\s*' + PERL6_IDENTIFIER_RANGE + '+)?',

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:594
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:594: DeprecationWarning: invalid escape sequence \s
    if re.search("(?:my|our|has)\s+(?:" + Perl6Lexer.PERL6_IDENTIFIER_RANGE +

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:595
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:595: DeprecationWarning: invalid escape sequence \s
    "+\s+)?[$@%&(]", text):

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:601
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:601: DeprecationWarning: invalid escape sequence \s
    if re.match('^\s*$', line):

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:605
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:605: DeprecationWarning: invalid escape sequence \s
    if re.match('^\s*(?:use\s+)?v6(?:\.\d(?:\.\d)?)?;', line):

.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:608
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/perl.py:608: DeprecationWarning: invalid escape sequence \s
    class_decl = re.match('^\s*(?:(?P<scope>my|our)\s+)?(?:module|class|role|enum|grammar)', line)

.tox/c1/lib/python3.6/site-packages/pygments/lexers/iolang.py:52
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/iolang.py:52: DeprecationWarning: invalid escape sequence \w
    ('[a-zA-Z_]\w*', Name),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/scripting.py:107
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/scripting.py:107: DeprecationWarning: invalid escape sequence \(
    ('\(', Punctuation, '#pop'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/scripting.py:699
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/scripting.py:699: DeprecationWarning: invalid escape sequence \(
    ('\(\*', Comment.Multiline, '#push'),

.tox/c1/lib/python3.6/site-packages/pygments/lexers/scripting.py:700
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/pygments/lexers/scripting.py:700: DeprecationWarning: invalid escape sequence \*
    ('\*\)', Comment.Multiline, '#pop'),

.tox/c1/lib/python3.6/site-packages/elasticsearch_dsl/document.py:215
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elasticsearch_dsl/document.py:215: DeprecationWarning: invalid escape sequence \s
    """

../invenio-indexer/invenio_indexer/cli.py:166
  /code/modules/invenio-indexer/invenio_indexer/cli.py:166: DeprecationWarning: 'resultcallback' has been renamed to 'result_callback'. The old name will be removed in Click 8.1.
    @queue.resultcallback()

.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:18
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:18: DeprecationWarning: invalid escape sequence \(
    SUB = re.compile("sub\(/(.*)/,\s+(.*)\)")

.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:19
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:19: DeprecationWarning: invalid escape sequence \(
    SPLIT = re.compile("split\((.),\s+(\d+),\s+(\d+|-1)\)")

.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:20
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:20: DeprecationWarning: invalid escape sequence \(
    STR = re.compile("str\(\)")

.tox/c1/lib/python3.6/site-packages/flask_caching/__init__.py:801
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/flask_caching/__init__.py:801: DeprecationWarning: invalid escape sequence \*
    """

.tox/c1/lib/python3.6/site-packages/elementpath/tdop_parser.py:434
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/tdop_parser.py:434: DeprecationWarning: invalid escape sequence \s
    s.replace(r'\ ', '\s+')

.tox/c1/lib/python3.6/site-packages/elementpath/tdop_parser.py:441
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/tdop_parser.py:441: DeprecationWarning: invalid escape sequence \s
    s = '%s\s*%s' % (s[:-4], s[-4:])

.tox/c1/lib/python3.6/site-packages/elementpath/tdop_parser.py:439
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/tdop_parser.py:439: DeprecationWarning: invalid escape sequence \s
    s = '%s\s*%s' % (s[:-2], s[-2:])

.tox/c1/lib/python3.6/site-packages/elementpath/xpath1_parser.py:32
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/xpath1_parser.py:32: DeprecationWarning: invalid escape sequence \-
    XML_NCNAME_PATTERN = u"[{0}][\-.0-9\u00B7\u0300-\u036F\u203F-\u2040{0}]*".format(XML_NAME_CHARACTER)

.tox/c1/lib/python3.6/site-packages/elementpath/xpath1_parser.py:115
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/xpath1_parser.py:115: DeprecationWarning: invalid escape sequence \s
    axis_pattern_template = '\\b%s(?=\s*\\:\\:|\s*\\(\\:.*\\:\\)\s*\\:\\:)'

.tox/c1/lib/python3.6/site-packages/elementpath/xpath1_parser.py:169
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/xpath1_parser.py:169: DeprecationWarning: invalid escape sequence \s
    function_pattern_template = '\\b%s(?=\s*\\(|\s*\\(\\:.*\\:\\)\\()'

.tox/c1/lib/python3.6/site-packages/elementpath/xpath2_parser.py:1045
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/elementpath/xpath2_parser.py:1045: DeprecationWarning: invalid escape sequence \s
    pattern='\\battribute(?=\s*\\:\\:|\s*\\(\\:.*\\:\\)\s*\\:\\:|\s*\\(|\s*\\(\\:.*\\:\\)\\()')

.tox/c1/lib/python3.6/site-packages/xmlschema/regex.py:39
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/xmlschema/regex.py:39: DeprecationWarning: invalid escape sequence \-
    u"\-.0-9:A-Z_a-z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-"

.tox/c1/lib/python3.6/site-packages/xmlschema/codepoints.py:31
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/xmlschema/codepoints.py:31: DeprecationWarning: invalid escape sequence \%
    return u'\%s' % unicode_chr(cp)

.tox/c1/lib/python3.6/site-packages/xmlschema/codepoints.py:35
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/xmlschema/codepoints.py:35: DeprecationWarning: invalid escape sequence \%
    start_char = u'\%s' % unicode_chr(cp[0])

.tox/c1/lib/python3.6/site-packages/xmlschema/codepoints.py:40
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/xmlschema/codepoints.py:40: DeprecationWarning: invalid escape sequence \%
    end_char = u'\%s' % unicode_chr(cp[1])

.tox/c1/lib/python3.6/site-packages/validators/url.py:5
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:5: DeprecationWarning: invalid escape sequence \.
    ip_middle_octet = u"(?:\.(?:1?\d{1,2}|2[0-4]\d|25[0-5]))"

.tox/c1/lib/python3.6/site-packages/validators/url.py:6
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:6: DeprecationWarning: invalid escape sequence \.
    ip_last_octet = u"(?:\.(?:[1-9]\d?|1\d\d|2[0-4]\d|25[0-4]))"

.tox/c1/lib/python3.6/site-packages/validators/url.py:13
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:13: DeprecationWarning: invalid escape sequence \S
    u"(?:\S+(?::\S*)?@)?"

.tox/c1/lib/python3.6/site-packages/validators/url.py:19
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:19: DeprecationWarning: invalid escape sequence \.
    u"(?:(?:169\.254|192\.168)" + ip_middle_octet + ip_last_octet + u")|"

.tox/c1/lib/python3.6/site-packages/validators/url.py:20
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:20: DeprecationWarning: invalid escape sequence \.
    u"(?:172\.(?:1[6-9]|2\d|3[0-1])" + ip_middle_octet + ip_last_octet + u"))"

.tox/c1/lib/python3.6/site-packages/validators/url.py:32
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:32: DeprecationWarning: invalid escape sequence \d
    u"(?:[1-9]\d?|1\d\d|2[01]\d|22[0-3])"

.tox/c1/lib/python3.6/site-packages/validators/url.py:39
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:39: DeprecationWarning: invalid escape sequence \.
    u"(?:\.(?:[a-z\u00a1-\uffff0-9]-?)*[a-z\u00a1-\uffff0-9]+)*"

.tox/c1/lib/python3.6/site-packages/validators/url.py:41
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:41: DeprecationWarning: invalid escape sequence \.
    u"(?:\.(?:[a-z\u00a1-\uffff]{2,}))"

.tox/c1/lib/python3.6/site-packages/validators/url.py:44
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:44: DeprecationWarning: invalid escape sequence \d
    u"(?::\d{2,5})?"

.tox/c1/lib/python3.6/site-packages/validators/url.py:46
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:46: DeprecationWarning: invalid escape sequence \S
    u"(?:/\S*)?"

.tox/c1/lib/python3.6/site-packages/validators/url.py:48
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/validators/url.py:48: DeprecationWarning: invalid escape sequence \?
    u"(?:\?\S*)?"

.tox/c1/lib/python3.6/site-packages/flask_oauthlib/contrib/cache.py:3
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/flask_oauthlib/contrib/cache.py:3: DeprecationWarning: 'werkzeug.contrib.cache' is deprecated as of version 0.15 and will be removed in version 1.0. It has moved to https://github.com/pallets/cachelib.
    from werkzeug.contrib.cache import NullCache, SimpleCache, FileSystemCache

.tox/c1/lib/python3.6/site-packages/webassets/filter/__init__.py:51
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/webassets/filter/__init__.py:51: DeprecationWarning: invalid escape sequence \,
    """

.tox/c1/lib/python3.6/site-packages/webassets/filter/replace.py:20
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/webassets/filter/replace.py:20: DeprecationWarning: invalid escape sequence \s
    """

.tox/c1/lib/python3.6/site-packages/semver/__init__.py:278
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/semver/__init__.py:278: DeprecationWarning: invalid escape sequence \d
    NUMERIC = re.compile("^\d+$")

.tox/c1/lib/python3.6/site-packages/semver/__init__.py:684
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/semver/__init__.py:684: DeprecationWarning: invalid escape sequence \s
    range_ = " ".join(re.split("\s+", range_))

.tox/c1/lib/python3.6/site-packages/semver/__init__.py:692
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/semver/__init__.py:692: DeprecationWarning: invalid escape sequence \s
    set_ = re.split("\s+", ' '.join([parse_comparator(comp, loose) for comp in range_.split(" ")]))

.tox/c1/lib/python3.6/site-packages/semver/__init__.py:744
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/semver/__init__.py:744: DeprecationWarning: invalid escape sequence \s
    for c in re.split("\s+", comp.strip())])

.tox/c1/lib/python3.6/site-packages/semver/__init__.py:785
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/semver/__init__.py:785: DeprecationWarning: invalid escape sequence \s
    for c in re.split("\s+", comp.strip())])

.tox/c1/lib/python3.6/site-packages/semver/__init__.py:836
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/semver/__init__.py:836: DeprecationWarning: invalid escape sequence \s
    for c in re.split("\s+", comp.strip())])

.tox/c1/lib/python3.6/site-packages/citeproc/formatter/rst.py:8
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/citeproc/formatter/rst.py:8: DeprecationWarning: invalid escape sequence \*
    text = text.replace('*', '\*')

.tox/c1/lib/python3.6/site-packages/citeproc/formatter/rst.py:9
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/citeproc/formatter/rst.py:9: DeprecationWarning: invalid escape sequence \`
    text = text.replace('`', '\`')

.tox/c1/lib/python3.6/site-packages/citeproc/model.py:671
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/citeproc/model.py:671: DeprecationWarning: invalid escape sequence \d
    m = re.search('\d+', first)

.tox/c1/lib/python3.6/site-packages/citeproc/source/bibtex/bibtex.py:156
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/citeproc/source/bibtex/bibtex.py:156: DeprecationWarning: invalid escape sequence \d
    RE_DAY = '(?P<day>\d+)'

.tox/c1/lib/python3.6/site-packages/citeproc/source/bibtex/bibtex.py:157
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/citeproc/source/bibtex/bibtex.py:157: DeprecationWarning: invalid escape sequence \w
    RE_MONTH = '(?P<month>\w+)'

.tox/c1/lib/python3.6/site-packages/b2handle/clientcredentials.py:102
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/b2handle/clientcredentials.py:102: DeprecationWarning: invalid escape sequence \*
    '''

.tox/c1/lib/python3.6/site-packages/b2handle/handleexceptions.py:128
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/b2handle/handleexceptions.py:128: DeprecationWarning: invalid escape sequence \s
    pat = re.compile('>[\s]+<')

.tox/c1/lib/python3.6/site-packages/past/translation/__init__.py:35
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/past/translation/__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
    import imp

.tox/c1/lib/python3.6/site-packages/past/types/oldstr.py:33
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/past/types/oldstr.py:33: DeprecationWarning: invalid escape sequence \d
    """

.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:177
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:177: DeprecationWarning: invalid escape sequence \*
    '''

.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:197
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:197: DeprecationWarning: invalid escape sequence \*
    '''

.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:230
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:230: DeprecationWarning: invalid escape sequence \*
    '''

.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:248
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:248: DeprecationWarning: invalid escape sequence \*
    '''

.tox/c1/bin/bagit.py:926
  /code/modules/weko-search-ui/.tox/c1/bin/bagit.py:926: DeprecationWarning: invalid escape sequence \c
    """

.tox/c1/src/pypdf2/PyPDF2/generic.py:348
  /code/modules/weko-search-ui/.tox/c1/src/pypdf2/PyPDF2/generic.py:348: DeprecationWarning: invalid escape sequence \c
    b_("c") : b_("\c"),

.tox/c1/lib/python3.6/site-packages/sickle/utils.py:20
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/sickle/utils.py:20: DeprecationWarning: invalid escape sequence \{
    return re.search('(\{.*\})', element.tag).group(1)

tests/test_api.py:158
  /code/modules/weko-search-ui/tests/test_api.py:158: DeprecationWarning: invalid escape sequence \s
    s = "\str"

tests/test_admin.py: 494 warnings
tests/test_api.py: 208 warnings
tests/test_ext.py: 78 warnings
tests/test_links.py: 26 warnings
tests/test_query.py: 234 warnings
tests/test_rest.py: 130 warnings
tests/test_tasks.py: 208 warnings
tests/test_utils.py: 7800 warnings
tests/test_views.py: 286 warnings
tests/test_weko_search_ui.py: 26 warnings
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/invenio_admin/ext.py:73: PendingDeprecationWarning: Usage of model and modelview kwargs are deprecated in favor of view_class, args and kwargs.
    PendingDeprecationWarning

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/passlib/pwd.py:363: DeprecationWarning: invalid escape sequence \*
    """

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/passlib/pwd.py:616: DeprecationWarning: invalid escape sequence \*
    """

tests/test_admin.py: 19 warnings
tests/test_api.py: 8 warnings
tests/test_ext.py: 3 warnings
tests/test_links.py: 1 warning
tests/test_query.py: 9 warnings
tests/test_rest.py: 5 warnings
tests/test_tasks.py: 8 warnings
tests/test_utils.py: 300 warnings
tests/test_views.py: 11 warnings
tests/test_weko_search_ui.py: 1 warning
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/flask_admin/model/base.py:1416: UserWarning: Fields missing from ruleset: created_userId,created_date,updated_userId,updated_date
    warnings.warn(text)

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/resync/w3c_datetime.py:105: DeprecationWarning: invalid escape sequence \d
    "(\d\d):(\d\d))$", s)

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/resync/list_base_with_index.py:412: DeprecationWarning: invalid escape sequence \w
    return(re.match('file:', uri) or not re.match('\w{3,4}:', uri))

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/resync/mapper.py:132: DeprecationWarning: invalid escape sequence \w
    path = re.sub('[^\w\-\.]', '_', path)

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/resync/mapper.py:134: DeprecationWarning: invalid escape sequence \.
    path = re.sub('[_\.]+$', '', path)

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/resync/mapper.py:135: DeprecationWarning: invalid escape sequence \.
    path = re.sub('^[_\.]+', '', path)

tests/test_admin.py::test_ItemManagementBulkDelete_index
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/resync/resource_list_builder.py:53: DeprecationWarning: invalid escape sequence \d
    self.exclude_files = ['sitemap\d{0,5}.xml']

tests/test_admin.py: 17 warnings
tests/test_query.py: 4 warnings
tests/test_rest.py: 2 warnings
tests/test_utils.py: 1 warning
  /code/modules/weko-search-ui/.tox/c1/lib/python3.6/site-packages/flask/sessions.py:208: UserWarning: "TEST_SERVER" is not a valid cookie domain, it must contain a ".". Add an entry to your hosts file, for example "TEST_SERVER.localdomain", and use that instead.
    ' "{rv}.localdomain", and use that instead.'.format(rv=rv)

tests/test_admin.py: 2688 warnings
tests/test_query.py: 768 warnings
tests/test_rest.py: 984 warnings
tests/test_utils.py: 2743 warnings
  /code/modules/invenio-oaiserver/invenio_oaiserver/receivers.py:28: DeprecationWarning: generator 'get_record_sets' raised StopIteration
    new_sets = set(get_record_sets(record=record))

tests/test_tasks.py::test_is_import_running
  /code/modules/weko-search-ui/.tox/c1/src/kombu/kombu/utils/compat.py:93: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.
    for ep in importlib_metadata.entry_points().get(namespace, [])

-- Docs: https://docs.pytest.org/en/stable/warnings.html

---------- coverage: platform linux, python 3.6.15-final-0 -----------
Name                            Stmts   Miss Branch BrPart  Cover
-----------------------------------------------------------------
weko_search_ui/__init__.py          4      0      0      0   100%
weko_search_ui/admin.py           363    124    134     17    61%
weko_search_ui/api.py             130      2     64      7    95%
weko_search_ui/bundles.py          19      0      0      0   100%
weko_search_ui/config.py          100      0      0      0   100%
weko_search_ui/ext.py              32      0     16      3    94%
weko_search_ui/links.py             5      0      0      0   100%
weko_search_ui/permissions.py       4      0      0      0   100%
weko_search_ui/query.py           624    157    306     66    70%
weko_search_ui/rest.py            269     53    122     28    74%
weko_search_ui/tasks.py            82     17     28      4    70%
weko_search_ui/utils.py          2097    984   1110    145    48%
weko_search_ui/version.py           2      0      0      0   100%
weko_search_ui/views.py           170    124     32      0    23%
-----------------------------------------------------------------
TOTAL                            3901   1461   1812    270    57%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml

=========================== short test summary info ============================
FAILED tests/test_admin.py::TestItemManagementBulkSearch::test_index_acl - As...
FAILED tests/test_admin.py::test_ItemImportView_check - flask_wtf.csrf.CSRFEr...
FAILED tests/test_admin.py::TestItemBulkExport::test_check_export_status - As...
FAILED tests/test_query.py::test_item_path_search_factory - assert '{"query":...
FAILED tests/test_query.py::test_function_issue35902 - AssertionError: assert...
FAILED tests/test_rest.py::test_IndexSearchResource_get_Exception - KeyError:...
FAILED tests/test_utils.py::test_delete_records - elasticsearch.exceptions.No...
FAILED tests/test_utils.py::test_get_feedback_mail_list - elasticsearch.excep...
FAILED tests/test_utils.py::test_unpackage_import_file - AssertionError: asse...
FAILED tests/test_utils.py::test_read_stats_file - sqlalchemy.exc.DataError: ...
FAILED tests/test_utils.py::test_handle_check_and_prepare_index_tree - KeyErr...
FAILED tests/test_utils.py::test_handle_check_and_prepare_index_tree2 - asser...
FAILED tests/test_utils.py::test_handle_check_and_prepare_feedback_mail - ela...
FAILED tests/test_utils.py::test_handle_check_cnri - TypeError: expected str,...
FAILED tests/test_utils.py::test_handle_check_doi - sqlalchemy.exc.StatementE...
FAILED tests/test_utils.py::test_handle_fill_system_item - sqlalchemy.exc.Pro...
ERROR tests/test_utils.py::test_up_load_file - elasticsearch.exceptions.Autho...
ERROR tests/test_utils.py::test_up_load_file - elasticsearch.exceptions.Autho...
ERROR tests/test_utils.py::test_register_item_metadata - elasticsearch.except...
ERROR tests/test_utils.py::test_update_publish_status - elasticsearch.excepti...
ERROR tests/test_utils.py::test_handle_workflow - elasticsearch.exceptions.Au...
ERROR tests/test_utils.py::test_send_item_created_event_to_es - elasticsearch...
ERROR tests/test_utils.py::test_import_items_to_system - elasticsearch.except...
ERROR tests/test_utils.py::test_handle_item_title - elasticsearch.exceptions....
ERROR tests/test_utils.py::test_handle_check_doi_indexes - elasticsearch.exce...
ERROR tests/test_utils.py::test_handle_check_doi_ra - elasticsearch.exception...
ERROR tests/test_utils.py::test_register_item_handle - elasticsearch.exceptio...
ERROR tests/test_utils.py::test_register_item_doi - elasticsearch.exceptions....
ERROR tests/test_utils.py::test_register_item_update_publish_status - elastic...
ERROR tests/test_utils.py::test_handle_doi_required_check - elasticsearch.exc...
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi0-after_doi0-warnings0-errors0-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi1-after_doi1-warnings1-errors1-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi2-after_doi2-warnings2-errors2-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi3-after_doi3-warnings3-errors3-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi4-after_doi4-warnings4-errors4-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi5-after_doi5-warnings5-errors5-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi6-after_doi6-warnings6-errors6-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi7-after_doi7-warnings7-errors7-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi8-after_doi8-warnings8-errors8-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi9-after_doi9-warnings9-errors9-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi10-after_doi10-warnings10-errors10-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi11-after_doi11-warnings11-errors11-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi12-after_doi12-warnings12-errors12-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi13-after_doi13-warnings13-errors13-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi14-after_doi14-warnings14-errors14-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi15-after_doi15-warnings15-errors15-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi16-after_doi16-warnings16-errors16-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi17-after_doi17-warnings17-errors17-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi18-after_doi18-warnings18-errors18-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi19-after_doi19-warnings19-errors19-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi20-after_doi20-warnings20-errors20-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi21-after_doi21-warnings21-errors21-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi22-after_doi22-warnings22-errors22-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi23-after_doi23-warnings23-errors23-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi24-after_doi24-warnings24-errors24-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi25-after_doi25-warnings25-errors25-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi26-after_doi26-warnings26-errors26-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi27-after_doi27-warnings27-errors27-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi28-after_doi28-warnings28-errors28-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi29-after_doi29-warnings29-errors29-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi30-after_doi30-warnings30-errors30-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi31-after_doi31-warnings31-errors31-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi32-after_doi32-warnings32-errors32-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[1-before_doi33-after_doi33-warnings33-errors33-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi34-after_doi34-warnings34-errors34-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi35-after_doi35-warnings35-errors35-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi36-after_doi36-warnings36-errors36-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi37-after_doi37-warnings37-errors37-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi38-after_doi38-warnings38-errors38-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi39-after_doi39-warnings39-errors39-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi40-after_doi40-warnings40-errors40-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi41-after_doi41-warnings41-errors41-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi42-after_doi42-warnings42-errors42-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi43-after_doi43-warnings43-errors43-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi44-after_doi44-warnings44-errors44-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi45-after_doi45-warnings45-errors45-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi46-after_doi46-warnings46-errors46-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi47-after_doi47-warnings47-errors47-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi48-after_doi48-warnings48-errors48-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi49-after_doi49-warnings49-errors49-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi50-after_doi50-warnings50-errors50-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi51-after_doi51-warnings51-errors51-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi52-after_doi52-warnings52-errors52-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi53-after_doi53-warnings53-errors53-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi54-after_doi54-warnings54-errors54-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi55-after_doi55-warnings55-errors55-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi56-after_doi56-warnings56-errors56-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi57-after_doi57-warnings57-errors57-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi58-after_doi58-warnings58-errors58-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi59-after_doi59-warnings59-errors59-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi60-after_doi60-warnings60-errors60-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi61-after_doi61-warnings61-errors61-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi62-after_doi62-warnings62-errors62-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi63-after_doi63-warnings63-errors63-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi64-after_doi64-warnings64-errors64-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi65-after_doi65-warnings65-errors65-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi66-after_doi66-warnings66-errors66-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[2-before_doi67-after_doi67-warnings67-errors67-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi68-after_doi68-warnings68-errors68-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi69-after_doi69-warnings69-errors69-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi70-after_doi70-warnings70-errors70-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi71-after_doi71-warnings71-errors71-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi72-after_doi72-warnings72-errors72-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi73-after_doi73-warnings73-errors73-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi74-after_doi74-warnings74-errors74-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi75-after_doi75-warnings75-errors75-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi76-after_doi76-warnings76-errors76-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi77-after_doi77-warnings77-errors77-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi78-after_doi78-warnings78-errors78-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi79-after_doi79-warnings79-errors79-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi80-after_doi80-warnings80-errors80-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi81-after_doi81-warnings81-errors81-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi82-after_doi82-warnings82-errors82-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi83-after_doi83-warnings83-errors83-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi84-after_doi84-warnings84-errors84-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi85-after_doi85-warnings85-errors85-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi86-after_doi86-warnings86-errors86-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi87-after_doi87-warnings87-errors87-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi88-after_doi88-warnings88-errors88-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi89-after_doi89-warnings89-errors89-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi90-after_doi90-warnings90-errors90-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi91-after_doi91-warnings91-errors91-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi92-after_doi92-warnings92-errors92-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi93-after_doi93-warnings93-errors93-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi94-after_doi94-warnings94-errors94-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi95-after_doi95-warnings95-errors95-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi96-after_doi96-warnings96-errors96-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi97-after_doi97-warnings97-errors97-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi98-after_doi98-warnings98-errors98-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi99-after_doi99-warnings99-errors99-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi100-after_doi100-warnings100-errors100-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[3-before_doi101-after_doi101-warnings101-errors101-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi102-after_doi102-warnings102-errors102-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi103-after_doi103-warnings103-errors103-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi104-after_doi104-warnings104-errors104-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi105-after_doi105-warnings105-errors105-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi106-after_doi106-warnings106-errors106-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi107-after_doi107-warnings107-errors107-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi108-after_doi108-warnings108-errors108-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi109-after_doi109-warnings109-errors109-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi110-after_doi110-warnings110-errors110-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi111-after_doi111-warnings111-errors111-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi112-after_doi112-warnings112-errors112-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi113-after_doi113-warnings113-errors113-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi114-after_doi114-warnings114-errors114-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi115-after_doi115-warnings115-errors115-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi116-after_doi116-warnings116-errors116-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi117-after_doi117-warnings117-errors117-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi118-after_doi118-warnings118-errors118-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi119-after_doi119-warnings119-errors119-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi120-after_doi120-warnings120-errors120-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi121-after_doi121-warnings121-errors121-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi122-after_doi122-warnings122-errors122-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi123-after_doi123-warnings123-errors123-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi124-after_doi124-warnings124-errors124-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi125-after_doi125-warnings125-errors125-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi126-after_doi126-warnings126-errors126-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi127-after_doi127-warnings127-errors127-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi128-after_doi128-warnings128-errors128-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi129-after_doi129-warnings129-errors129-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi130-after_doi130-warnings130-errors130-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi131-after_doi131-warnings131-errors131-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi132-after_doi132-warnings132-errors132-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi133-after_doi133-warnings133-errors133-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi134-after_doi134-warnings134-errors134-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[4-before_doi135-after_doi135-warnings135-errors135-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi136-after_doi136-warnings136-errors136-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi137-after_doi137-warnings137-errors137-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi138-after_doi138-warnings138-errors138-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi139-after_doi139-warnings139-errors139-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi140-after_doi140-warnings140-errors140-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi141-after_doi141-warnings141-errors141-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi142-after_doi142-warnings142-errors142-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi143-after_doi143-warnings143-errors143-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi144-after_doi144-warnings144-errors144-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi145-after_doi145-warnings145-errors145-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi146-after_doi146-warnings146-errors146-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi147-after_doi147-warnings147-errors147-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi148-after_doi148-warnings148-errors148-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi149-after_doi149-warnings149-errors149-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi150-after_doi150-warnings150-errors150-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi151-after_doi151-warnings151-errors151-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi152-after_doi152-warnings152-errors152-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi153-after_doi153-warnings153-errors153-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi154-after_doi154-warnings154-errors154-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi155-after_doi155-warnings155-errors155-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi156-after_doi156-warnings156-errors156-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi157-after_doi157-warnings157-errors157-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi158-after_doi158-warnings158-errors158-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi159-after_doi159-warnings159-errors159-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi160-after_doi160-warnings160-errors160-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi161-after_doi161-warnings161-errors161-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi162-after_doi162-warnings162-errors162-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi163-after_doi163-warnings163-errors163-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi164-after_doi164-warnings164-errors164-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi165-after_doi165-warnings165-errors165-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi166-after_doi166-warnings166-errors166-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi167-after_doi167-warnings167-errors167-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi168-after_doi168-warnings168-errors168-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi169-after_doi169-warnings169-errors169-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi170-after_doi170-warnings170-errors170-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi171-after_doi171-warnings171-errors171-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi172-after_doi172-warnings172-errors172-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi173-after_doi173-warnings173-errors173-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi174-after_doi174-warnings174-errors174-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi175-after_doi175-warnings175-errors175-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi176-after_doi176-warnings176-errors176-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi177-after_doi177-warnings177-errors177-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi178-after_doi178-warnings178-errors178-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi179-after_doi179-warnings179-errors179-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi180-after_doi180-warnings180-errors180-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi181-after_doi181-warnings181-errors181-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[5-before_doi182-after_doi182-warnings182-errors182-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi183-after_doi183-warnings183-errors183-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi184-after_doi184-warnings184-errors184-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi185-after_doi185-warnings185-errors185-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi186-after_doi186-warnings186-errors186-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi187-after_doi187-warnings187-errors187-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi188-after_doi188-warnings188-errors188-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi189-after_doi189-warnings189-errors189-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi190-after_doi190-warnings190-errors190-False-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi191-after_doi191-warnings191-errors191-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi192-after_doi192-warnings192-errors192-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi193-after_doi193-warnings193-errors193-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi194-after_doi194-warnings194-errors194-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi195-after_doi195-warnings195-errors195-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi196-after_doi196-warnings196-errors196-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi197-after_doi197-warnings197-errors197-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi198-after_doi198-warnings198-errors198-True-False]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi199-after_doi199-warnings199-errors199-True-True]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi200-after_doi200-warnings200-errors200-True-True]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi201-after_doi201-warnings201-errors201-True-True]
ERROR tests/test_utils.py::test_handle_fill_system_item3[None-before_doi202-after_doi202-warnings202-errors202-True-True]
ERROR tests/test_utils.py::test_get_thumbnail_key - sqlalchemy.exc.Operationa...
ERROR tests/test_utils.py::test_handle_check_metadata_not_existed - sqlalchem...
ERROR tests/test_utils.py::test_handle_get_all_id_in_item_type - sqlalchemy.e...
ERROR tests/test_utils.py::test_export_all - elasticsearch.exceptions.Authori...
ERROR tests/test_utils.py::test_delete_exported - sqlalchemy.exc.OperationalE...
ERROR tests/test_utils.py::test_cancel_export_all - sqlalchemy.exc.Operationa...
ERROR tests/test_utils.py::test_get_export_status - sqlalchemy.exc.Operationa...
ERROR tests/test_utils.py::test_handle_check_item_is_locked - sqlalchemy.exc....
ERROR tests/test_utils.py::test_handle_remove_es_metadata - elasticsearch.exc...
ERROR tests/test_utils.py::test_check_index_access_permissions - sqlalchemy.e...
ERROR tests/test_utils.py::test_function_issue34520[1-before_doi0-after_doi0-warnings0-errors0-True]
ERROR tests/test_utils.py::test_function_issue34535 - sqlalchemy.exc.Operatio...
ERROR tests/test_utils.py::test_function_issue34958 - sqlalchemy.exc.Operatio...
ERROR tests/test_utils.py::test_handle_fill_system_item_issue34520[1-before_doi0-after_doi0-warnings0-errors0-True]
ERROR tests/test_utils.py::test_handle_fill_system_item_issue34520[1000-before_doi1-after_doi1-warnings1-errors1-True]
ERROR tests/test_utils.py::test_handle_check_exist_record_issue35315[1-http://TEST_SERVER/records/1-warnings0-errors0-keep]
ERROR tests/test_utils.py::test_handle_check_exist_record_issue35315[1000-http://TEST_SERVER/records/1-warnings1-errors1-None]
ERROR tests/test_utils.py::test_handle_check_exist_record_issue35315[1000-http://TEST_SERVER/records/1000-warnings2-errors2-None]
ERROR tests/test_utils.py::test_handle_check_exist_record_issue35315[None-None-warnings3-errors3-new]
ERROR tests/test_views.py::test_search - sqlalchemy.exc.OperationalError: (ps...
ERROR tests/test_views.py::test_search_acl_guest - sqlalchemy.exc.Operational...
ERROR tests/test_views.py::test_search_acl[3-200] - sqlalchemy.exc.Operationa...
ERROR tests/test_views.py::test_opensearch_description - sqlalchemy.exc.Opera...
ERROR tests/test_views.py::test_opensearch_description_acl_guest - sqlalchemy...
ERROR tests/test_views.py::test_journal_detail - sqlalchemy.exc.OperationalEr...
ERROR tests/test_views.py::test_search_feedback_mail_list - sqlalchemy.exc.Op...
ERROR tests/test_views.py::test_get_child_list - sqlalchemy.exc.OperationalEr...
ERROR tests/test_views.py::test_get_path_name_dict - sqlalchemy.exc.Operation...
ERROR tests/test_views.py::test_gettitlefacet - sqlalchemy.exc.OperationalErr...
ERROR tests/test_views.py::test_get_last_item_id - sqlalchemy.exc.Operational...
=== 16 failed, 116 passed, 17209 warnings, 247 errors in 2690.89s (0:44:50) ====
ERROR: InvocationError for command /code/modules/weko-search-ui/.tox/c1/bin/pytest --cov=weko_search_ui tests -v --cov-branch --cov-report=term --cov-report=xml --cov-report=html --cov-config=tox.ini --basetemp=/code/modules/weko-search-ui/.tox/c1/tmp (exited with code 1)
___________________________________ summary ____________________________________
ERROR:   c1: commands failed
